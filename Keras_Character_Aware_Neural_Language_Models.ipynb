{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "[View in Colaboratory](https://colab.research.google.com/github/stikbuf/Language_Modeling/blob/master/Keras_Character_Aware_Neural_Language_Models.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4_0CMzmyQXoy"
   },
   "source": [
    "## Configure the cloud environment\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QB7JyNTfQfKF"
   },
   "source": [
    "### Mount Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 2539
    },
    "colab_type": "code",
    "id": "oTB-axrvQiZU",
    "outputId": "e2997ab7-5a01-4406-d696-aae0c2c981aa"
   },
   "outputs": [],
   "source": [
    "# Install a Drive FUSE wrapper.\n",
    "# https://github.com/astrada/google-drive-ocamlfuse\n",
    "!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
    "!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
    "!apt-get update -qq 2>&1 > /dev/null\n",
    "!apt-get -y install -qq google-drive-ocamlfuse fuse\n",
    "\n",
    "\n",
    "# Generate auth tokens for Colab\n",
    "from google.colab import auth\n",
    "auth.authenticate_user()\n",
    "\n",
    "\n",
    "# Generate creds for the Drive FUSE library.\n",
    "from oauth2client.client import GoogleCredentials\n",
    "creds = GoogleCredentials.get_application_default()\n",
    "import getpass\n",
    "!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
    "vcode = getpass.getpass()\n",
    "!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "zVhUtsJjQqy5",
    "outputId": "fbf684be-5cab-471f-ed07-2cc929cc4e7d"
   },
   "outputs": [],
   "source": [
    "# If you got a \"Transport endpoint is not connected.\" error. Please run this line first to unmount the drive.\n",
    "# See https://stackoverflow.com/questions/49588113/google-colab-script-throws-transport-endpoint-is-not-connected?utm_medium=organic&utm_source=google_rich_qa&utm_campaign=google_rich_qa\n",
    "!fusermount -u drive\n",
    "\n",
    "# Create a directory and mount Google Drive using that directory.\n",
    "!mkdir -p drive\n",
    "!google-drive-ocamlfuse drive\n",
    "a = !ls drive/\n",
    "print('Files in Drive:', a)\n",
    "assert a!=[], 'Drive should not be empty!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 126
    },
    "colab_type": "code",
    "id": "bvfVOCzkRErx",
    "outputId": "2b10a93a-4be4-457f-ff93-749ace078ab4"
   },
   "outputs": [],
   "source": [
    "local_path='./drive/share_with_me/AI/Character-aware_LM/'\n",
    "#local_path='./'\n",
    "import sys\n",
    "sys.path.append(local_path)\n",
    "!ls './drive/share_with_me/AI/Character-aware_LM/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "TbWRANsEQr6U",
    "outputId": "fbedffd8-9029-4ca3-c73c-b87c6a74bfe6"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "#assert tf.test.gpu_device_name() != '', \"GPU not avaliable!\"\n",
    "tf.test.gpu_device_name()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yUldvgY1RH0S"
   },
   "source": [
    "## Load data (Penn Tree bank -- PTB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_path='./'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5NgfjuJbPoz9"
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\" # Use single card. THIS LINE MUST BE RUN BEFORE TENSORFLOW IS IMPORTED\n",
    "import pylab\n",
    "%pylab inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib  \n",
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "from reader import ptb_raw_data, ptb_producer # by Google"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "dpHEJHNnPo0U",
    "outputId": "78431c7b-a03d-4609-a381-9d7aa5b96632"
   },
   "outputs": [],
   "source": [
    "train_data, valid_data, test_data, word_to_id = ptb_raw_data(local_path + 'data') # tokens\n",
    "id_to_word = dict((v, k) for k, v in word_to_id.items())\n",
    "voc_size = len(id_to_word)\n",
    "voc_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Train data size: {0}, Valid data size: {1}, Test data size: {2}\\n'.\n",
    "      format(len(train_data), len(valid_data), len(test_data)))\n",
    "print('train/val/test_data is a list, some elements in train_data is', train_data[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "oZ8sUleQSoWQ",
    "outputId": "c4796a76-4fe3-48a3-f62a-bef541f937b0"
   },
   "outputs": [],
   "source": [
    "id_to_word[voc_size]='<SS>' # Add start word token '<SS>'\n",
    "id_to_word[voc_size+1]='<EE>' # Add end word token '<EE>'\n",
    "word_to_id = dict((v, k) for k, v in id_to_word.items())\n",
    "voc_size = len(id_to_word)\n",
    "voc_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "colab_type": "code",
    "id": "zj8IWqJ8Po0h",
    "outputId": "5e9fded6-d6d9-44f1-dfa6-9fdece6f2df4"
   },
   "outputs": [],
   "source": [
    "word_id = pd.DataFrame.from_dict(word_to_id, orient='index').sort_values(by=0, ascending=True)\n",
    "word_id.columns = ['id']\n",
    "print(word_id.head())\n",
    "print(word_id.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "colab_type": "code",
    "id": "uxPQPQqMPo0t",
    "outputId": "946af7f2-7906-4fa3-f2bc-d1d7bffe5428"
   },
   "outputs": [],
   "source": [
    "id_word = pd.DataFrame.from_dict(id_to_word, orient='index')\n",
    "id_word.columns = ['word']\n",
    "print(id_word.head())\n",
    "print(id_word.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "colab_type": "code",
    "id": "Hz5IRBM6Po04",
    "outputId": "3d885c2d-15f3-4176-e943-1ae2ed489515"
   },
   "outputs": [],
   "source": [
    "' '.join([id_to_word[id] for id in train_data[:50]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = 35"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GDwfc2jpPo1D"
   },
   "source": [
    "# RNN baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KPQMjhyePo1F"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "from tensorflow.python.keras.utils import to_categorical \n",
    "\n",
    "def gen_word_word(batch_size=128, dataset='train'):\n",
    "    assert dataset in ['train', 'valid', 'test'], 'Dataset must be train or valid or test.'\n",
    "    \n",
    "    dic = {'train':train_data, 'valid':valid_data, 'test':test_data}\n",
    "    data = dic[dataset]\n",
    "    \n",
    "    while True:\n",
    "        rnd_idxs = list(range(len(data)-seq_len-1))\n",
    "        random.shuffle(rnd_idxs)\n",
    "        cnt = 0\n",
    "        while cnt < len(rnd_idxs) - batch_size :\n",
    "            X = np.array([[word_to_id['<SS>']] + data[i:i+seq_len] + [word_to_id['<EE>']]\n",
    "                          for i in rnd_idxs[cnt:cnt+batch_size]])\n",
    "            Y = X[:,1:]\n",
    "            X = X[:,:-1]\n",
    "            Y = to_categorical(Y, num_classes=voc_size)\n",
    "            #print(X.shape)\n",
    "            cnt += batch_size\n",
    "            yield X, Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JL6Za0iNPo1O"
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import GRU, Dense, Embedding, InputLayer, Dropout\n",
    "from tensorflow.python.keras.optimizers import RMSprop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add dropout between layers, see [Recurrent Neural Network Regularization](https://arxiv.org/abs/1409.2329)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Pt6IvftHPo1Y"
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "embedding_size = 128\n",
    "\n",
    "\n",
    "model.add(Embedding(input_dim=voc_size,\n",
    "                    output_dim=embedding_size,\n",
    "                    name='inputEmbedding'))\n",
    "model.add(GRU(units=128, return_sequences=True))\n",
    "model.add(Dropout(0.3)) \n",
    "model.add(GRU(units=64, return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(voc_size, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we denote $w_{1:T} = [w_1, w_2,...,w_T ]$ to be the sequence of words in thes, training involves minimizing\n",
    "the negative log-likelihood ($NLL$)\n",
    "$$NLL = - \\sum_{t=1}^{T} \\log Pr (w_t | w_{1:t-1})$$\n",
    "i.e. the Crossentropy loss (with out averaging).  \n",
    "As is standard in language modeling, we use perplexity(PPL) to evaluate the performance of our models. Perplexity of a model over a sequence $[w_1, w_2,...,w_T ]$ is given by\n",
    "$$PPL = e^\\frac{NLL}{T} = e^{ave (Crossentropy)}$$\n",
    "where $NLL/Crossentropy$ is calculated over the test set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Evcq5fYye8jt"
   },
   "outputs": [],
   "source": [
    "# perplexity\n",
    "def PPL(y_true, y_pred):\n",
    "    return tf.exp(tf.reduce_mean(tf.keras.backend.categorical_crossentropy(y_true, y_pred)))\n",
    "\n",
    "def ACC(y_true, y_pred):\n",
    "    ACC = tf.equal(tf.argmax(y_true, axis = 2), \n",
    "                   tf.argmax(y_pred, axis = 2))\n",
    "    ACC = tf.cast(ACC, tf.float32)\n",
    "\n",
    "    return tf.reduce_mean(ACC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KRoe-64bZAWz"
   },
   "outputs": [],
   "source": [
    "optimizer = RMSprop(lr=1e-3)\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=[ACC, PPL])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 290
    },
    "colab_type": "code",
    "id": "efPbWtAJPo2P",
    "outputId": "c9bf68c6-3436-44f3-e4e4-04b33a82dfd0"
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.callbacks import TensorBoard, ModelCheckpoint\n",
    "import os\n",
    "if not os.path.exists(local_path + 'model/'):\n",
    "    os.mkdir(local_path + 'model/')\n",
    "\n",
    "path_model = local_path + 'model/model.keras'    \n",
    "tensorboard = TensorBoard(log_dir='log')\n",
    "checkpoint = ModelCheckpoint(filepath=path_model, verbose=1,\n",
    "                             monitor='val_PPL',mode='min' ,save_best_only='True')\n",
    "# path_model = local_path + 'model/model.keras'\n",
    "# model.save(path_model)\n",
    "\n",
    "callback_lists=[tensorboard,checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 3677
    },
    "colab_type": "code",
    "id": "7rWihlHePo2Z",
    "outputId": "19ef2c40-5173-42d2-e4ff-d43ff273cd1d"
   },
   "outputs": [],
   "source": [
    "history = model.fit_generator(generator=gen_word_word(), \n",
    "                           steps_per_epoch=50, epochs=125,\n",
    "                           callbacks=callback_lists,\n",
    "                           validation_data=gen_word_word(dataset='valid'),\n",
    "                           validation_steps=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G2l21JdFPo3A"
   },
   "outputs": [],
   "source": [
    "logs = pd.DataFrame(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 301
    },
    "colab_type": "code",
    "id": "jQLqEZwRPo3M",
    "outputId": "9e0c5672-82b6-4fdb-8f11-739eb0007baa"
   },
   "outputs": [],
   "source": [
    "print(logs.columns)\n",
    "pylab.rcParams['figure.figsize'] = (13, 8)\n",
    "logs.loc[1:,['PPL','val_PPL']].plot() # start with 1 makes the figure prettier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kI9DyqjoPo3s"
   },
   "outputs": [],
   "source": [
    "# path_model = local_path + 'model/model.keras'\n",
    "# model.save(path_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "V_USEcjEPo3x"
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.models import load_model\n",
    "\n",
    "model_restore = load_model(path_model, custom_objects={'ACC':ACC,'PPL': PPL})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1129
    },
    "colab_type": "code",
    "id": "9iSl3szGPo37",
    "outputId": "150689c7-d3fb-4935-9184-dfc4ec6ef708",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "history = model_restore.fit_generator(generator=gen_word_word(), \n",
    "                           steps_per_epoch=50, epochs=3,\n",
    "                           callbacks=callback_lists,\n",
    "                           validation_data=gen_word_word(dataset='valid'),\n",
    "                           validation_steps=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 301
    },
    "colab_type": "code",
    "id": "WPNTJojePo4D",
    "outputId": "8b2ce958-73e2-4498-9f01-78d2f5d49a86"
   },
   "outputs": [],
   "source": [
    "logs = pd.DataFrame(history.history)\n",
    "print(logs.columns)\n",
    "pylab.rcParams['figure.figsize'] = (13, 8)\n",
    "logs.loc[:,['PPL','val_PPL']].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SY8V79vOPo4N"
   },
   "outputs": [],
   "source": [
    "def predict_seq(model, preSeq=None, genLen=seq_len, power=1):\n",
    "    \"\"\" Predict a sequence with length genLen.\n",
    "        arg:\n",
    "            model: Keras model used to predict.\n",
    "            preSeq: list. The leading sequence.\n",
    "            genLen: float or np.inf. If power is equal to np.inf, then an argmax will be used. \n",
    "            power: Probility power.\n",
    "    \"\"\"\n",
    "    preSeq = [word_to_id['<SS>']] if preSeq == None else [word_to_id['<SS>']] + preSeq   \n",
    "    pointer = len(preSeq) - 1\n",
    "    \n",
    "    for _ in range(genLen):\n",
    "        inputSeq = np.array([preSeq])\n",
    "        prob = model.predict(inputSeq)[0, pointer, :]\n",
    "        if power==np.inf:\n",
    "            pred = np.argmax(prob)\n",
    "        else:\n",
    "            prob = np.power(prob, power)\n",
    "            prob = prob / np.sum(prob)\n",
    "            pred = np.random.choice(range(voc_size), p=prob)\n",
    "        preSeq.append(pred)\n",
    "        pointer = pointer + 1\n",
    "\n",
    "    return preSeq, ' '.join([id_to_word[id] for id in preSeq])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, seq = predict_seq(model, power=1)\n",
    "seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Character aware model\n",
    "\n",
    "[Character-Aware Neural Language Models -- arxiv-1508.06615 -- AAAI 2016](https://arxiv.org/abs/1508.06615)\n",
    "\n",
    "[Ref: Github/jarfo/kchar](https://github.com/jarfo/kchar)\n",
    "\n",
    "\n",
    "![model](https://github.com/stikbuf/Language_Modeling/blob/master/Character%20aware.png?raw=true)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fKog3W-MPo4c"
   },
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### convert to text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_text = [id_to_word[idx] for idx in train_data]\n",
    "valid_data_text = [id_to_word[idx] for idx in valid_data]\n",
    "test_data_text = [id_to_word[idx] for idx in test_data]\n",
    "total_data_text = train_data_text + valid_data_text + test_data_text\n",
    "\n",
    "maxWordLen = max([len(word) for word in total_data_text])\n",
    "maxWordLen += 2 # Inclued Start and End character\n",
    "\n",
    "ds = pd.Series([len(word) for word in total_data_text])\n",
    "plt.figure(figsize=(10,5))\n",
    "ds.plot.hist(bins=range(1, maxWordLen))\n",
    "plt.title('word length distribution, max={0}, min={1}'.\n",
    "          format(ds.max(), ds.min()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### merge chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = []\n",
    "for word in total_data_text:\n",
    "    chars.extend(list(word))\n",
    "    \n",
    "ds = pd.Series(chars)\n",
    "plt.figure(figsize=(15,10))   \n",
    "matplotlib.rc('xtick', labelsize=20)\n",
    "matplotlib.rc('ytick', labelsize=15)\n",
    "ds.value_counts().plot.bar()\n",
    "plt.title('character distribution, total {0} characters(without \\'S\\' and \\'E\\')'.format(len(set(chars))))\n",
    "plt.show()\n",
    "\n",
    "chars = list(set(chars + ['S'] + ['E'] + [' ']))\n",
    "# 'S' for word leading char, 'E' for word ending char, space for padding\n",
    "id_to_chars = dict(enumerate(chars))\n",
    "chars_to_id = dict((v, k) for k,v in id_to_chars.items())\n",
    "num_chars = len(chars)\n",
    "\n",
    "print('number of chars:', num_chars, '\\n')\n",
    "print(chars, '\\n')\n",
    "print(id_to_chars, '\\n')\n",
    "print(chars_to_id, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_to_charId(wordId):\n",
    "    # Convert word to a string of word Ids\n",
    "    wordString = 'S' + id_to_word[wordId].center(maxWordLen - 2) + 'E'\n",
    "    return [chars_to_id[char] for char in wordString]\n",
    "\n",
    "def wordSeq_charSeq(bWordSeq):\n",
    "    batch, seqLen = bWordSeq.shape\n",
    "    bWordSeq = bWordSeq.ravel()\n",
    "    charSeq = np.array([word_to_charId(wordId) for wordId in bWordSeq])\n",
    "    return charSeq.reshape(batch, seqLen, -1)\n",
    "\n",
    "word_to_charId(word_to_id['the']) # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "from tensorflow.python.keras.utils import to_categorical \n",
    "\n",
    "def gen_char_word(batch_size=128, dataset='train'):\n",
    "    assert dataset in ['train', 'valid', 'test'], 'Dataset must be train or valid or test.'\n",
    "    \n",
    "    dic = {'train':train_data, 'valid':valid_data, 'test':test_data}\n",
    "    data = dic[dataset]\n",
    "    \n",
    "    while True:\n",
    "        rnd_idxs = list(range(len(data)-seq_len-1))\n",
    "        random.shuffle(rnd_idxs)\n",
    "        cnt = 0\n",
    "        while cnt < len(rnd_idxs) - batch_size :\n",
    "            X = np.array([[word_to_id['<SS>']] + data[i:i+seq_len] + [word_to_id['<EE>']]\n",
    "                          for i in rnd_idxs[cnt:cnt+batch_size]])\n",
    "            Y = X[:,1:]\n",
    "            X = X[:,:-1]\n",
    "            Y = to_categorical(Y, num_classes=voc_size)\n",
    "            X = wordSeq_charSeq(X) \n",
    "            #print(X.shape)\n",
    "            cnt += batch_size\n",
    "            yield X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(next(gen_char_word(batch_size=1, dataset='train'))[1][0][2].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## option"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Option():\n",
    "    def __init__(self):\n",
    "        self.batch_size = 20\n",
    "        self.seq_length = seq_len + 1\n",
    "        self.max_word_l = maxWordLen # Include Start and End character\n",
    "        self.char_vocab_size = num_chars\n",
    "        self.char_vec_size = 15\n",
    "        self.feature_maps = [50,100,150,200,200,200,200]\n",
    "        self.kernels = [1,2,3,4,5,6,7]\n",
    "        self.highway_layers = 2\n",
    "        self.num_lstm_layers = 2\n",
    "        self.rnn_size = 128\n",
    "        self.word_vocab_size = voc_size\n",
    "        self.dropout = 0.5\n",
    "        self.learing_rate = 1e-5\n",
    "        \n",
    "opt = Option()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN\n",
    "![CNN part](https://github.com/stikbuf/Language_Modeling/blob/master/Character%20aware-CNN.png?raw=true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.layers import Conv2D, MaxPooling2D, Concatenate, Reshape\n",
    "\n",
    "def CNN(seq_length, length, feature_maps, kernels, x):\n",
    "\n",
    "    concat_input = []\n",
    "    for feature_map, kernel in zip(feature_maps, kernels):\n",
    "        reduced_l = length - kernel + 1\n",
    "        conv = Conv2D(feature_map, (1, kernel), activation='tanh', data_format=\"channels_last\")(x)\n",
    "        maxp = MaxPooling2D((1, reduced_l), data_format=\"channels_last\")(conv)\n",
    "        concat_input.append(maxp)\n",
    "\n",
    "    x = Concatenate()(concat_input)\n",
    "    x = Reshape((seq_length, sum(feature_maps)))(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Highway Network  \n",
    "[Srivastava et al.](https://arxiv.org/abs/1505.00387)\n",
    "\n",
    "Input vector is $\\textbf{y}$, then layer output $\\textbf{z}$ is\n",
    "$$\\textbf{z = t} \\odot g(\\textbf{W}_H\\textbf{y}+\\textbf{b}_H) + \\textbf{(1 - t)} \\odot \\textbf{y}$$\n",
    "where \n",
    "$$\\textbf{t} = \\sigma(\\textbf{W}_T\\textbf{y}+\\textbf{b}_T)$$\n",
    "\n",
    "$\\textbf{t}$ is called the\n",
    "*transform gate*, and $(\\textbf{1}âˆ’\\textbf{t})$ is called the *carry gate*. \n",
    "Similar to the memory cells in LSTM networks, highway layers allow for training of deep networks by adaptively carrying some dimensions of the input directly to the output. By construction the dimensions of $\\textbf{y}$ and $\\textbf{z}$ have to match, and hence $\\textbf{W}_T$ and $\\textbf{W}_H$ are square matrices. **Basically, a highway layer is a dense layer with residual connection modulated by an adaptive gate.**\n",
    "\n",
    "A keras model is also a keras layer! So you can combine some keras layers to design your own layer. This is useful when combining with TimeDistributed wrapper. [See section 3 in this blog](https://keunwoochoi.wordpress.com/2016/11/18/for-beginners-writing-a-custom-keras-layer/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras import backend as K\n",
    "from tensorflow.python.keras.layers import Dense, Activation, Multiply, Add, Lambda, Input\n",
    "from tensorflow.python.keras.initializers import Constant\n",
    "from tensorflow.python.keras.models import Model\n",
    "\n",
    "class LambdaWithShape(Lambda):\n",
    "#     def __init__(self, function, **kwargs):\n",
    "#         super(LambdaWithShape, self).__init__(function, **kwargs)\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape\n",
    "\n",
    "def Highway(value, nLayers, activation='tanh', gateBias=-3):\n",
    "    dim = K.int_shape(value)[-1]\n",
    "    gateBiasInitalizer = Constant(gateBias)\n",
    "    for i in range(nLayers):\n",
    "        tGate = Dense(units=dim, bias_initializer=gateBiasInitalizer)(value)\n",
    "        tGate = Activation('sigmoid')(tGate)\n",
    "        #cGate = Lambda(lambda x: 1.0-x)(tGate) # WARNING:tensorflow:All custom layers should implement the `compute_output_shape`\n",
    "        cGate = LambdaWithShape(lambda x: 1.0-x)(tGate) # I do not specify output_shape\n",
    "        transformed = Dense(units=dim, bias_initializer=gateBiasInitalizer)(value)\n",
    "        transformed = Activation(activation)(value)\n",
    "        transformedGate = Multiply()([tGate, transformed])\n",
    "        identityGate = Multiply()([cGate, value])\n",
    "        value = Add()([transformedGate, identityGate])\n",
    "    return value\n",
    "\n",
    "inputs = Input((sum(opt.feature_maps),))\n",
    "HighwayLayer = Model(inputs=inputs, outputs=Highway(inputs, nLayers=opt.highway_layers))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.layers import Input, Embedding, GRU, Dropout, BatchNormalization, TimeDistributed\n",
    "#from tensorflow.python.keras.optimizers import SGD\n",
    "\n",
    "#chars = Input(batch_shape=(opt.batch_size, opt.seq_length, opt.max_word_l), name='chars')\n",
    "chars = Input(shape=(opt.seq_length, opt.max_word_l), name='chars') # will get a warning if you do not specify batch_shape\n",
    "chars_embedding = Embedding(opt.char_vocab_size, opt.char_vec_size, name='chars_embedding')(chars)\n",
    "cnn = CNN(opt.seq_length, opt.max_word_l, opt.feature_maps, opt.kernels, chars_embedding)\n",
    "x = cnn\n",
    "inputs = chars\n",
    "\n",
    "x = BatchNormalization()(x)\n",
    "\n",
    "x = TimeDistributed(HighwayLayer)(x)\n",
    "highway = x\n",
    "\n",
    "for l in range(opt.num_lstm_layers):\n",
    "    #x = GRU(opt.rnn_size, return_sequences=True, stateful=True)(x)\n",
    "    x = GRU(opt.rnn_size, return_sequences=True, stateful=False)(x)\n",
    "\n",
    "    if opt.dropout > 0:\n",
    "        x = Dropout(opt.dropout)(x)\n",
    "        \n",
    "output = Dense(opt.word_vocab_size, activation='softmax')(x)\n",
    "\n",
    "modelCAware = Model(inputs=inputs, outputs=output)\n",
    "modelCAware.summary()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelConvWordFeatureBeforeHighway = Model(inputs=inputs, outputs=cnn)\n",
    "modelConvWordFeatureAfterHighway = Model(inputs=inputs, outputs=highway)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perplexity\n",
    "def PPL(y_true, y_pred):\n",
    "    return tf.exp(tf.reduce_mean(tf.keras.backend.categorical_crossentropy(y_true, y_pred)))\n",
    "\n",
    "def ACC(y_true, y_pred):\n",
    "    ACC = tf.equal(tf.argmax(y_true, axis = 2), \n",
    "                   tf.argmax(y_pred, axis = 2))\n",
    "    ACC = tf.cast(ACC, tf.float32)\n",
    "\n",
    "    return tf.reduce_mean(ACC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.optimizers import RMSprop\n",
    "\n",
    "optimizer = RMSprop(lr=opt.learing_rate)\n",
    "modelCAware.compile(loss='categorical_crossentropy', optimizer='rmsprop',metrics=[ACC, PPL])  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tensorboard histograms\n",
    "Keras has a bug in TensorBoard visualization, see https://github.com/keras-team/keras/issues/3358  \n",
    "DO NOT set show_hist_gram=True  unless you want TensorBoard visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_hist_gram = True "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.callbacks import TensorBoard, ModelCheckpoint\n",
    "import os\n",
    "if not os.path.exists(local_path + 'model/'):\n",
    "    os.mkdir(local_path + 'model/')\n",
    "\n",
    "path_model = local_path + 'model/modelAware.keras'\n",
    "if show_hist_gram:\n",
    "    tensorboard = TensorBoard(log_dir='log', histogram_freq=1, write_grads=True)\n",
    "else:\n",
    "    tensorboard = TensorBoard(log_dir='log')\n",
    "checkpoint = ModelCheckpoint(filepath=path_model, verbose=1,\n",
    "                             monitor='val_PPL',mode='min' ,save_best_only='True')\n",
    "# path_model = local_path + 'model/model.keras'\n",
    "# model.save(path_model)\n",
    "\n",
    "callback_lists=[tensorboard,checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if show_hist_gram:\n",
    "    history = modelCAware.fit_generator(generator=gen_char_word(batch_size=opt.batch_size), \n",
    "                           steps_per_epoch=50, epochs=5,\n",
    "                           callbacks=callback_lists, \n",
    "                           #validation_data=gen_char_word(batch_size=opt.batch_size, dataset='valid'),#ValueError: If printing histograms, validation_data must be provided, and cannot be a generator.\n",
    "                           validation_data=next(gen_char_word(batch_size=(len(valid_data)-seq_len-2)//100, dataset='valid')),  # //100 to avoid memory error.        \n",
    "                           validation_steps=None) \n",
    "else:\n",
    "    history = modelCAware.fit_generator(generator=gen_char_word(batch_size=opt.batch_size), \n",
    "                           steps_per_epoch=50, epochs=5,\n",
    "                           callbacks=callback_lists, \n",
    "                           validation_data=gen_char_word(batch_size=opt.batch_size, dataset='valid'),#ValueError: If printing histograms, validation_data must be provided, and cannot be a generator.\n",
    "                           #validation_data=next(gen_char_word(batch_size=(len(valid_data)-seq_len-2)//100, dataset='valid')),  # //10 to avoid memory error. DO NOT use this line unless you want TensorBoard visualization       \n",
    "                           validation_steps=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logs = pd.DataFrame(history.history)\n",
    "print(logs.columns)\n",
    "pylab.rcParams['figure.figsize'] = (13, 8)\n",
    "logs.loc[1:,['PPL','val_PPL']].plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word feature analysis\n",
    "The convolution and the highway network can be viewed as a word feature extractor. Let's establish some intuition by the following experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractWordFeature(words, extcModel=modelConvWordFeatureAfterHighway):\n",
    "    \"\"\"\n",
    "    words: List of word text.\n",
    "    extcModel: Extractor model.\n",
    "    \n",
    "    returns: Pandas dataframe. Index is the word, corresponding to the feature vector.\n",
    "    \"\"\"\n",
    "    \n",
    "    padWord = lambda word: 'S' + word.lower().center(opt.max_word_l - 2) + 'E' # pad a single word\n",
    "    wordsPadedCroped = [padWord(word[:opt.max_word_l-2]) for word in words] # cut input word if it is too long\n",
    "    #print(wordsPadedCroped)\n",
    "    wordsPadedCroped = [[chars_to_id[char] for char in word] for word in wordsPadedCroped] # convert to char index\n",
    "    #print(wordsPadedCroped)\n",
    "    \n",
    "    # split into batches, list of tuples\n",
    "    batches = []\n",
    "    while wordsPadedCroped != []:\n",
    "        if len(wordsPadedCroped)>opt.seq_length:\n",
    "            batches.append((np.array(wordsPadedCroped[:opt.seq_length]), opt.seq_length))\n",
    "            wordsPadedCroped = wordsPadedCroped[opt.seq_length:]\n",
    "        else:\n",
    "            wLast = wordsPadedCroped + [[chars_to_id[' ']]*opt.max_word_l]*(opt.seq_length-len(wordsPadedCroped))         \n",
    "            batches.append((np.array(wLast), len(wordsPadedCroped)))\n",
    "            wordsPadedCroped = []   \n",
    "    \n",
    "    features = []\n",
    "    for batch in batches:\n",
    "        data = batch[0]\n",
    "        validNum = batch[1]\n",
    "        features.append(extcModel.predict(np.expand_dims(data,0))[0,:validNum,:])\n",
    "    \n",
    "    features = np.vstack(features)\n",
    "    \n",
    "    # return a dataframe\n",
    "    features = pd.DataFrame(data=features, index=words)\n",
    "    features.index.name = 'featVecs'\n",
    "    features.columns.name = 'vecDims'\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampleWordList = ['look','looks','looked','looking','lok','looooooook',\n",
    "                  'lk','loop','lock','locked','cook','see','observation',\n",
    "                  'hear','run','reading','news','book','computer',\n",
    "                  'programming','python','java','lisp','c#','matlab','jupyter']\n",
    "vocWordList = list(word_id.index)\n",
    "print(vocWordList[:5], '......', vocWordList[-4:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "def sortedWordsByDistance(queryWord, Words, metric='cosine', \n",
    "                          extcModel=modelConvWordFeatureBeforeHighway):\n",
    "    \"\"\"\n",
    "    queryWord: Single query word\n",
    "    Words: Words to compare\n",
    "    metric: metrics -- 'cosine',euclidean','correlation',...\n",
    "    \"\"\"\n",
    "    queryWordFeat = extractWordFeature([queryWord], extcModel=extcModel)\n",
    "    wordFeats = extractWordFeature(Words, extcModel=extcModel) \n",
    "    \n",
    "    dis = pd.Series(cdist(queryWordFeat, wordFeats, metric=metric)[0])\n",
    "    dis.index = Words\n",
    "    dis = dis.sort_values(ascending=True)\n",
    "    return dis\n",
    "    \n",
    "    \n",
    "sortedDis = sortedWordsByDistance('look', sampleWordList)\n",
    "sortedDis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smpFeatures = extractWordFeature(sampleWordList, extcModel=modelConvWordFeatureAfterHighway)\n",
    "smpFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "def featureVis(feautres, usePCA=True):\n",
    "    \"\"\"\n",
    "    features: A pandas dataframe. Index should be words, values should be word features.\n",
    "    \"\"\"\n",
    "    wordList = feautres.index\n",
    "    featTransed = feautres.values\n",
    "    if usePCA:\n",
    "        featTransed = PCA(n_components=len(feautres.columns)//7).fit_transform(featTransed)\n",
    "    featTransed = TSNE(n_components=2).fit_transform(featTransed)\n",
    "    featTransed = pd.DataFrame(featTransed, index=wordList)\n",
    "    featTransed.index.name = 'featVecs'\n",
    "    featTransed.columns.name = 'vecDims'\n",
    "\n",
    "    pylab.rcParams['figure.figsize'] = (13, 8)\n",
    "    axes = featTransed.plot.scatter(x=0, y=1)\n",
    "    for txt in wordList:\n",
    "        axes.annotate(txt, (featTransed.loc[txt,0],featTransed.loc[txt,1]))\n",
    "        \n",
    "featureVis(smpFeatures, usePCA=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocFeatures = extractWordFeature(vocWordList, extcModel=modelConvWordFeatureAfterHighway)\n",
    "vocFeatures.head(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "sample = vocFeatures.sample(200)\n",
    "featureVis(sample, usePCA=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gated CNN model\n",
    "\n",
    "[Language Modeling with Gated Convolutional Networks -- arxiv-1612.08083 -- Facebook AI Research](https://arxiv.org/abs/1612.08083)\n",
    "![Gated CNN model](https://github.com/stikbuf/Language_Modeling/blob/master/Gated%20CNN.png?raw=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data generator\n",
    "\n",
    "Same as RNN baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "from tensorflow.python.keras.utils import to_categorical \n",
    "\n",
    "def gen_word_word(batch_size=128, dataset='train'):\n",
    "    assert dataset in ['train', 'valid', 'test'], 'Dataset must be train or valid or test.'\n",
    "    \n",
    "    dic = {'train':train_data, 'valid':valid_data, 'test':test_data}\n",
    "    data = dic[dataset]\n",
    "    \n",
    "    while True:\n",
    "        rnd_idxs = list(range(len(data)-seq_len-1))\n",
    "        random.shuffle(rnd_idxs)\n",
    "        cnt = 0\n",
    "        while cnt < len(rnd_idxs) - batch_size :\n",
    "            X = np.array([[word_to_id['<SS>']] + data[i:i+seq_len] + [word_to_id['<EE>']]\n",
    "                          for i in rnd_idxs[cnt:cnt+batch_size]])\n",
    "            Y = X[:,1:]\n",
    "            X = X[:,:-1]\n",
    "            Y = to_categorical(Y, num_classes=voc_size)\n",
    "            #print(X.shape)\n",
    "            cnt += batch_size\n",
    "            yield X, Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n",
    "\n",
    "The tf integrated keras does not support causal convolution, i.e. padding param can not be 'causal' in Conv1D. (see [WaveNet: A Generative Model for Raw Audio, section 2.1.](https://arxiv.org/abs/1609.03499) ), so we use original keras instead.\n",
    "\n",
    "![causal convolutional layers](https://github.com/stikbuf/Language_Modeling/blob/dev/figures/causal_convolution.png?raw=true)\n",
    "\n",
    "I recommend that you read the paper section 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "keras.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model config\n",
    "![model configuration](https://github.com/stikbuf/Language_Modeling/blob/dev/figures/gCNNConfig.png?raw=true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedding_size=128 in the paper\n",
    "GCNN_13 = [ [(4, 1268)] ]*1 ,\\\n",
    "          [ [(4,1268), (4,1268)] ]*12 \n",
    "    \n",
    "GCNN_14B = [ [(5, 512)] ]*1 ,\\\n",
    "           [ [(1,128), (5,128), (1,512)] ]*3 ,\\\n",
    "           [ [(1,512), (5,512), (1,1024)] ]*3 ,\\\n",
    "           [ [(1,1024), (5,1024), (1,2048)] ]*6 ,\\\n",
    "            [ [(1,1024), (5,1024), (1,4096)] ]*1 \n",
    "            \n",
    "GCNN_9 = [ [(4, 807)] ]*1 ,\\\n",
    "          [ [(4,807), (4,807)] ]*4  \n",
    "    \n",
    "GCNN_8B = [ [(1, 512)] ]*1 ,\\\n",
    "           [ [(1,128), (5,128), (1,512)] ]*3 ,\\\n",
    "           [ [(1,256), (5,256), (1,512)] ]*3 ,\\\n",
    "           [ [(1,1024), (1,1024), (1,2048)] ]*1 \n",
    "\n",
    "# embedding_size=208 in the paper\n",
    "GCNN_8 = [ [(4, 900)] ]*1 ,\\\n",
    "           [ [(4,900)] ]*7\n",
    "\n",
    "GCNN_14 = [ [(6, 850)] ]*3 ,\\\n",
    "           [ [(1,850)] ]*1 ,\\\n",
    "           [ [(5,850)] ]*4 ,\\\n",
    "           [ [(1,850)] ]*1 ,\\\n",
    "            [ [(4,850)] ]*3 ,\\\n",
    "            [ [(4,1024)] ]*1 ,\\\n",
    "            [ [(4,2048)] ]*1  \n",
    "    \n",
    "modelParam = GCNN_8B\n",
    "modelParam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I call:  \n",
    "\"(4, 1268)\" a unit  \n",
    "\"[(4, 1268), (4, 1268)]\" a block  \n",
    "\"[(4, 1268), (4, 1268)] * 12\" a chunk  \n",
    "A model is made by chunks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GLU layer:\n",
    "$$h_l(X) = (\\textbf{X} * \\textbf{W} + \\textbf{b}) \\otimes \\sigma(\\textbf{X} * \\textbf{V} + \\textbf{c})$$\n",
    "implemented in `gatedCNNUnit()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Conv1D, Multiply, Add, Input, Dense, Embedding\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "\n",
    "def gatedCNNUnit(kernel_size=3, filters=1024, input_shape=None):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    conv = Conv1D(filters=filters, kernel_size=kernel_size, data_format='channels_last',\n",
    "                  strides=1, padding='causal')(inputs)\n",
    "    gated = Conv1D(filters=filters, kernel_size=kernel_size, data_format='channels_last',\n",
    "                   strides=1, padding='causal', activation='sigmoid')(inputs)\n",
    "    value = Multiply()([conv, gated])\n",
    "    return Model(inputs=inputs, outputs=value)\n",
    "    \n",
    "    \n",
    "def gatedCNNChunk(chunk, input_shape):\n",
    "    origin = Input(shape=input_shape)\n",
    "    inputs = origin\n",
    "    for block in chunk:\n",
    "        x = inputs\n",
    "        for unit in block:\n",
    "            kernel_size, filters = unit\n",
    "            x = gatedCNNUnit(kernel_size=kernel_size, filters=filters, input_shape=K.int_shape(x)[1:])(x)\n",
    "        if K.int_shape(inputs)[-1] != K.int_shape(x)[-1]: # see Eqn.(2).in arxiv-1512.03385\n",
    "            inputs = Dense( K.int_shape(x)[-1])(inputs)\n",
    "            #print('DIM CHANGE IN RES MOD!!')\n",
    "        x = Add()([inputs, x])\n",
    "        inputs = x\n",
    "    return Model(inputs=origin, outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_size = 128\n",
    "\n",
    "inputs = Input(shape=(None,))\n",
    "x = Embedding(input_dim=voc_size,\n",
    "              output_dim=embedding_size)(inputs)\n",
    "for chunk in modelParam:\n",
    "    x = gatedCNNChunk(chunk, K.int_shape(x)[1:])(x)\n",
    "\n",
    "x = Dense(voc_size, activation='softmax')(x)\n",
    "gCNNModel = Model(inputs=inputs, outputs=x)\n",
    "gCNNModel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perplexity\n",
    "def PPL(y_true, y_pred):\n",
    "    return tf.exp(tf.reduce_mean(tf.keras.backend.categorical_crossentropy(y_true, y_pred)))\n",
    "\n",
    "def ACC(y_true, y_pred):\n",
    "    ACC = tf.equal(tf.argmax(y_true, axis = 2), \n",
    "                   tf.argmax(y_pred, axis = 2))\n",
    "    ACC = tf.cast(ACC, tf.float32)\n",
    "\n",
    "    return tf.reduce_mean(ACC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import RMSprop\n",
    "\n",
    "optimizer = RMSprop(lr=1e-4)\n",
    "gCNNModel.compile(optimizer=optimizer,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=[ACC, PPL])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import TensorBoard, ModelCheckpoint\n",
    "import os\n",
    "if not os.path.exists(local_path + 'model/'):\n",
    "    os.mkdir(local_path + 'model/')\n",
    "\n",
    "path_model = local_path + 'model/model.keras'    \n",
    "tensorboard = TensorBoard(log_dir='log')\n",
    "checkpoint = ModelCheckpoint(filepath=path_model, verbose=1,\n",
    "                             monitor='val_PPL',mode='min' ,save_best_only='True')\n",
    "# path_model = local_path + 'model/model.keras'\n",
    "# model.save(path_model)\n",
    "\n",
    "callback_lists=[tensorboard,checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = gCNNModel.fit_generator(generator=gen_word_word(batch_size=16), \n",
    "                           steps_per_epoch=100, epochs=30,\n",
    "                           callbacks=callback_lists,\n",
    "                           validation_data=gen_word_word(dataset='valid'),\n",
    "                           validation_steps=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logs = pd.DataFrame(history.history)\n",
    "print(logs.columns)\n",
    "pylab.rcParams['figure.figsize'] = (13, 8)\n",
    "logs.loc[1:,['PPL','val_PPL']].plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_seq(model, preSeq=None, genLen=seq_len, power=1):\n",
    "    \"\"\" Predict a sequence with length genLen.\n",
    "        arg:\n",
    "            model: Keras model used to predict.\n",
    "            preSeq: list. The leading sequence.\n",
    "            genLen: float or np.inf. If power is equal to np.inf, then an argmax will be used. \n",
    "            power: Probility power.\n",
    "    \"\"\"\n",
    "    preSeq = [word_to_id['<SS>']] if preSeq == None else [word_to_id['<SS>']] + preSeq   \n",
    "    pointer = len(preSeq) - 1\n",
    "    \n",
    "    for _ in range(genLen):\n",
    "        inputSeq = np.array([preSeq])\n",
    "        prob = model.predict(inputSeq)[0, pointer, :]\n",
    "        if power==np.inf:\n",
    "            pred = np.argmax(prob)\n",
    "        else:\n",
    "            prob = np.power(prob, power)\n",
    "            prob = prob / np.sum(prob)\n",
    "            pred = np.random.choice(range(voc_size), p=prob)\n",
    "        preSeq.append(pred)\n",
    "        pointer = pointer + 1\n",
    "\n",
    "    return preSeq, ' '.join([id_to_word[id] for id in preSeq])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, seq = predict_seq(gCNNModel, power=1)\n",
    "seq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Memory networks model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Option"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OptionMemNet():\n",
    "    def __init__(self):\n",
    "        self.batch_size = 128\n",
    "        self.seq_length = seq_len + 1\n",
    "        self.dropout = 0.5\n",
    "        self.learing_rate = 1e-5\n",
    "        \n",
    "optMemNet = OptionMemNet()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data generator\n",
    "\n",
    "X is also categorical data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "from tensorflow.python.keras.utils import to_categorical \n",
    "\n",
    "def gen_word_word(batch_size=128, dataset='train'):\n",
    "    assert dataset in ['train', 'valid', 'test'], 'Dataset must be train or valid or test.'\n",
    "    \n",
    "    dic = {'train':train_data, 'valid':valid_data, 'test':test_data}\n",
    "    data = dic[dataset]\n",
    "    \n",
    "    while True:\n",
    "        rnd_idxs = list(range(len(data)-seq_len-1))\n",
    "        random.shuffle(rnd_idxs)\n",
    "        cnt = 0\n",
    "        while cnt < len(rnd_idxs) - batch_size :\n",
    "            X = np.array([[word_to_id['<SS>']] + data[i:i+seq_len] + [word_to_id['<EE>']]\n",
    "                          for i in rnd_idxs[cnt:cnt+batch_size]])\n",
    "            Y = X[:,1:]\n",
    "            X = X[:,:-1]\n",
    "            X = to_categorical(X, num_classes=voc_size)\n",
    "            Y = to_categorical(Y, num_classes=voc_size)\n",
    "            #print(X.shape)\n",
    "            cnt += batch_size\n",
    "            yield X, Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tensorflow model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "inputs = tf.placeholder(tf.float32, shape=(optMemNet.batch_size, optMemNet.seq_length, voc_size), name='input')\n",
    "y_true = tf.placeholder(tf.float32, shape=(optMemNet.batch_size, optMemNet.seq_length, voc_size), name='tureWords')\n",
    "\n",
    "def batch_matMul(X, Y):\n",
    "    b, n, m = X.get_shape()\n",
    "    m, c = Y.get_shape()\n",
    "\n",
    "    X = tf.reshape(X, [-1, m])\n",
    "    h = tf.matmul(X, Y)\n",
    "    h = tf.reshape(h, [-1, n, c])\n",
    "    return h\n",
    "\n",
    "def MemoryLayer(name, extMemory, inMemorySize=128, fitOutW=None, updateHopH=False, RNNLike=True):\n",
    "    \"\"\"\n",
    "    Keras-like Memory Layer\n",
    "    name: layer name\n",
    "    Memory: memory tensor\n",
    "    memorySize: the length of the internel memory tensor\n",
    "    fitOutW: int or None. None for disable. Int for output dimension of the final linear transormation.\n",
    "    updateHopH: boolean. Whether use a linear transormation H to update u between hops.\n",
    "                see Section 2.2 RNN-like\n",
    "    \"\"\"\n",
    "    batch, seqLen, extMemorySize = extMemory.get_shape() # extMemory shape (batch, seqLen, extMemorySize)\n",
    "    print('shape of extMemory:', extMemory.get_shape())\n",
    "    sharedName = 'MEMNET' if RNNLike else name\n",
    "    \n",
    "    def Layer(inputTensor): # query, shape: (batch, seqLen, querySize)\n",
    "        with tf.variable_scope(name):\n",
    "            _, _, querySize = inputTensor.get_shape()\n",
    "            print('shape of inputTensor:', inputTensor.get_shape())\n",
    "            # (querySize, inMemorySize)\n",
    "            embB = tf.get_variable('embB', shape=(querySize, inMemorySize), dtype=tf.float32,\n",
    "                                   initializer=tf.contrib.layers.xavier_initializer())\n",
    "            u = batch_matMul(inputTensor, embB) # u, shape: (batch, seqLen, inMemorySize)\n",
    "            print('shape of u:', u.get_shape())\n",
    "            \n",
    "        with tf.variable_scope(sharedName, reuse=tf.AUTO_REUSE):\n",
    "            embA = tf.get_variable('embA', shape=(extMemorySize, inMemorySize), dtype=tf.float32,\n",
    "                                   initializer=tf.contrib.layers.xavier_initializer())\n",
    "            M = batch_matMul(extMemory, embA) # shape: (batch, seqLen, inMemorySize)\n",
    "            print('shape of M:', M.get_shape())\n",
    "\n",
    "            p = tf.nn.softmax(tf.matmul(M,tf.transpose(u, perm=(0,2,1))), axis=1) # shape: (batch, seqLen, seqLen)\n",
    "            print('shape of p:', p.get_shape())\n",
    "             \n",
    "            embC = tf.get_variable('embC', shape=(extMemorySize, inMemorySize), dtype=tf.float32,\n",
    "                                   initializer=tf.contrib.layers.xavier_initializer())\n",
    "            C = batch_matMul(extMemory, embC) # shape: (batch, seqLen, inMemorySize)\n",
    "            print('shape of C:', C.get_shape())\n",
    "            \n",
    "        with tf.variable_scope(name):\n",
    "            O = tf.matmul(tf.transpose(p, perm=(0,2,1)), C)\n",
    "            if updateHopH:\n",
    "                H = tf.get_variable('H', shape=(inMemorySize, inMemorySize))\n",
    "                u = batch_matMul(u, H)\n",
    "            O = tf.add(O, u) #shape: (batch, seqLen, inMemorySize)\n",
    "            O = tf.nn.relu(O)\n",
    "\n",
    "            if fitOutW:\n",
    "                W = tf.get_variable('W', shape=(inMemorySize, fitOutW))\n",
    "                O = batch_matMul(O, W)\n",
    "            print('shape of O:', O.get_shape())\n",
    "            return O\n",
    "            \n",
    "    return Layer\n",
    "\n",
    "x = inputs\n",
    "tf.ones(shape=x.get_shape())\n",
    "x = MemoryLayer('Mem1', inputs, updateHopH=True)(0.1*tf.ones(shape=x.get_shape())) # see paper\n",
    "x = MemoryLayer('Mem2', inputs, fitOutW=voc_size)(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits_v2(logits=x, labels=y_true)\n",
    "loss = tf.reduce_mean(cross_entropy)\n",
    "PPL = tf.exp(loss)\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=1e-3).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = tf.Session()\n",
    "session.run(tf.global_variables_initializer())\n",
    "\n",
    "for i in range(630):\n",
    "    x_batch, y_true_batch = next(gen_word_word(batch_size=optMemNet.batch_size))\n",
    "    feed_dict_train = {inputs: x_batch, y_true: y_true_batch}\n",
    "    _, trainPPL = session.run([optimizer, PPL], feed_dict=feed_dict_train)\n",
    "    print('On iter {0} with training PPL: {1}'.format(i, trainPPL))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Keras - Character-Aware Neural Language Models.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
