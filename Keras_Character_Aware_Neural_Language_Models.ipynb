{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "[View in Colaboratory](https://colab.research.google.com/github/stikbuf/Language_Modeling/blob/master/Keras_Character_Aware_Neural_Language_Models.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4_0CMzmyQXoy"
   },
   "source": [
    "## Configure the cloud environment\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QB7JyNTfQfKF"
   },
   "source": [
    "### Mount Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 2539
    },
    "colab_type": "code",
    "id": "oTB-axrvQiZU",
    "outputId": "e2997ab7-5a01-4406-d696-aae0c2c981aa"
   },
   "outputs": [],
   "source": [
    "# Install a Drive FUSE wrapper.\n",
    "# https://github.com/astrada/google-drive-ocamlfuse\n",
    "!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
    "!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
    "!apt-get update -qq 2>&1 > /dev/null\n",
    "!apt-get -y install -qq google-drive-ocamlfuse fuse\n",
    "\n",
    "\n",
    "# Generate auth tokens for Colab\n",
    "from google.colab import auth\n",
    "auth.authenticate_user()\n",
    "\n",
    "\n",
    "# Generate creds for the Drive FUSE library.\n",
    "from oauth2client.client import GoogleCredentials\n",
    "creds = GoogleCredentials.get_application_default()\n",
    "import getpass\n",
    "!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
    "vcode = getpass.getpass()\n",
    "!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "zVhUtsJjQqy5",
    "outputId": "fbf684be-5cab-471f-ed07-2cc929cc4e7d"
   },
   "outputs": [],
   "source": [
    "# If you got a \"Transport endpoint is not connected.\" error. Please run this line first to unmount the drive.\n",
    "# See https://stackoverflow.com/questions/49588113/google-colab-script-throws-transport-endpoint-is-not-connected?utm_medium=organic&utm_source=google_rich_qa&utm_campaign=google_rich_qa\n",
    "!fusermount -u drive\n",
    "\n",
    "# Create a directory and mount Google Drive using that directory.\n",
    "!mkdir -p drive\n",
    "!google-drive-ocamlfuse drive\n",
    "a = !ls drive/\n",
    "print('Files in Drive:', a)\n",
    "assert a!=[], 'Drive should not be empty!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 126
    },
    "colab_type": "code",
    "id": "bvfVOCzkRErx",
    "outputId": "2b10a93a-4be4-457f-ff93-749ace078ab4"
   },
   "outputs": [],
   "source": [
    "local_path='./drive/share_with_me/AI/Character-aware_LM/'\n",
    "#local_path='./'\n",
    "import sys\n",
    "sys.path.append(local_path)\n",
    "!ls './drive/share_with_me/AI/Character-aware_LM/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "TbWRANsEQr6U",
    "outputId": "fbedffd8-9029-4ca3-c73c-b87c6a74bfe6"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "#assert tf.test.gpu_device_name() != '', \"GPU not avaliable!\"\n",
    "tf.test.gpu_device_name()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yUldvgY1RH0S"
   },
   "source": [
    "## Load data (Penn Tree bank -- PTB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_path='./'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5NgfjuJbPoz9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/IPython/core/magics/pylab.py:160: UserWarning: pylab import has clobbered these variables: ['pylab']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n",
      "  \"\\n`%matplotlib` prevents importing * from pylab and numpy\"\n",
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\" # Use single card. THIS LINE MUST BE RUN BEFORE TENSORFLOW IS IMPORTED\n",
    "import pylab\n",
    "%pylab inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib  \n",
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "from reader import ptb_raw_data, ptb_producer # by Google"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "dpHEJHNnPo0U",
    "outputId": "78431c7b-a03d-4609-a381-9d7aa5b96632"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data, valid_data, test_data, word_to_id = ptb_raw_data(local_path + 'data') # tokens\n",
    "id_to_word = dict((v, k) for k, v in word_to_id.items())\n",
    "voc_size = len(id_to_word)\n",
    "voc_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data size: 929589, Valid data size: 73760, Test data size: 82430\n",
      "\n",
      "train/val/test_data is a list, some elements in train_data is [9970, 9971, 9972, 9974, 9975, 9976, 9980, 9981, 9982, 9983]\n"
     ]
    }
   ],
   "source": [
    "print('Train data size: {0}, Valid data size: {1}, Test data size: {2}\\n'.\n",
    "      format(len(train_data), len(valid_data), len(test_data)))\n",
    "print('train/val/test_data is a list, some elements in train_data is', train_data[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "oZ8sUleQSoWQ",
    "outputId": "c4796a76-4fe3-48a3-f62a-bef541f937b0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10002"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_to_word[voc_size]='<SS>' # Add start word token '<SS>'\n",
    "id_to_word[voc_size+1]='<EE>' # Add end word token '<EE>'\n",
    "word_to_id = dict((v, k) for k, v in id_to_word.items())\n",
    "voc_size = len(id_to_word)\n",
    "voc_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "colab_type": "code",
    "id": "zj8IWqJ8Po0h",
    "outputId": "5e9fded6-d6d9-44f1-dfa6-9fdece6f2df4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       id\n",
      "the     0\n",
      "<unk>   1\n",
      "<eos>   2\n",
      "N       3\n",
      "of      4\n",
      "              id\n",
      "ssangyong   9997\n",
      "swapo       9998\n",
      "wachter     9999\n",
      "<SS>       10000\n",
      "<EE>       10001\n"
     ]
    }
   ],
   "source": [
    "word_id = pd.DataFrame.from_dict(word_to_id, orient='index').sort_values(by=0, ascending=True)\n",
    "word_id.columns = ['id']\n",
    "print(word_id.head())\n",
    "print(word_id.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "colab_type": "code",
    "id": "uxPQPQqMPo0t",
    "outputId": "946af7f2-7906-4fa3-f2bc-d1d7bffe5428"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    word\n",
      "0    the\n",
      "1  <unk>\n",
      "2  <eos>\n",
      "3      N\n",
      "4     of\n",
      "            word\n",
      "9997   ssangyong\n",
      "9998       swapo\n",
      "9999     wachter\n",
      "10000       <SS>\n",
      "10001       <EE>\n"
     ]
    }
   ],
   "source": [
    "id_word = pd.DataFrame.from_dict(id_to_word, orient='index')\n",
    "id_word.columns = ['word']\n",
    "print(id_word.head())\n",
    "print(id_word.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "colab_type": "code",
    "id": "Hz5IRBM6Po04",
    "outputId": "3d885c2d-15f3-4176-e943-1ae2ed489515"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'aer banknote berlitz calloway centrust cluett fromstein gitano guterman hydro-quebec ipo kia memotec mlx nahb punts rake regatta rubens sim snack-food ssangyong swapo wachter <eos> pierre <unk> N years old will join the board as a nonexecutive director nov. N <eos> mr. <unk> is chairman of <unk> n.v. the dutch'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join([id_to_word[id] for id in train_data[:50]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = 35"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GDwfc2jpPo1D"
   },
   "source": [
    "# RNN baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KPQMjhyePo1F"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "from tensorflow.python.keras.utils import to_categorical \n",
    "\n",
    "def gen_word_word(batch_size=128, dataset='train'):\n",
    "    assert dataset in ['train', 'valid', 'test'], 'Dataset must be train or valid or test.'\n",
    "    \n",
    "    dic = {'train':train_data, 'valid':valid_data, 'test':test_data}\n",
    "    data = dic[dataset]\n",
    "    \n",
    "    while True:\n",
    "        rnd_idxs = list(range(len(data)-seq_len-1))\n",
    "        random.shuffle(rnd_idxs)\n",
    "        cnt = 0\n",
    "        while cnt < len(rnd_idxs) - batch_size :\n",
    "            X = np.array([[word_to_id['<SS>']] + data[i:i+seq_len] + [word_to_id['<EE>']]\n",
    "                          for i in rnd_idxs[cnt:cnt+batch_size]])\n",
    "            Y = X[:,1:]\n",
    "            X = X[:,:-1]\n",
    "            Y = to_categorical(Y)\n",
    "            #print(X.shape)\n",
    "            cnt += batch_size\n",
    "            yield X, Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JL6Za0iNPo1O"
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import GRU, Dense, Embedding, InputLayer, Dropout\n",
    "from tensorflow.python.keras.optimizers import RMSprop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add dropout between layers, see [Recurrent Neural Network Regularization](https://arxiv.org/abs/1409.2329)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Pt6IvftHPo1Y"
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "embedding_size = 128\n",
    "\n",
    "\n",
    "model.add(Embedding(input_dim=voc_size,\n",
    "                    output_dim=embedding_size,\n",
    "                    name='inputEmbedding'))\n",
    "model.add(GRU(units=128, return_sequences=True))\n",
    "model.add(Dropout(0.3)) \n",
    "model.add(GRU(units=64, return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(voc_size, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we denote $w_{1:T} = [w_1, w_2,...,w_T ]$ to be the sequence of words in thes, training involves minimizing\n",
    "the negative log-likelihood ($NLL$)\n",
    "$$NLL = - \\sum_{t=1}^{T} \\log Pr (w_t | w_{1:t-1})$$\n",
    "i.e. the Crossentropy loss (with out averaging).  \n",
    "As is standard in language modeling, we use perplexity(PPL) to evaluate the performance of our models. Perplexity of a model over a sequence $[w_1, w_2,...,w_T ]$ is given by\n",
    "$$PPL = e^\\frac{NLL}{T} = e^{ave (Crossentropy)}$$\n",
    "where $NLL/Crossentropy$ is calculated over the test set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Evcq5fYye8jt"
   },
   "outputs": [],
   "source": [
    "# perplexity\n",
    "def PPL(y_true, y_pred):\n",
    "    return tf.exp(tf.reduce_mean(tf.keras.backend.categorical_crossentropy(y_true, y_pred)))\n",
    "\n",
    "def ACC(y_true, y_pred):\n",
    "    ACC = tf.equal(tf.argmax(y_true, axis = 2), \n",
    "                   tf.argmax(y_pred, axis = 2))\n",
    "    ACC = tf.cast(ACC, tf.float32)\n",
    "\n",
    "    return tf.reduce_mean(ACC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KRoe-64bZAWz"
   },
   "outputs": [],
   "source": [
    "optimizer = RMSprop(lr=1e-3)\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=[ACC, PPL])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 290
    },
    "colab_type": "code",
    "id": "efPbWtAJPo2P",
    "outputId": "c9bf68c6-3436-44f3-e4e4-04b33a82dfd0"
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.callbacks import TensorBoard, ModelCheckpoint\n",
    "import os\n",
    "if not os.path.exists(local_path + 'model/'):\n",
    "    os.mkdir(local_path + 'model/')\n",
    "\n",
    "path_model = local_path + 'model/model.keras'    \n",
    "tensorboard = TensorBoard(log_dir='log')\n",
    "checkpoint = ModelCheckpoint(filepath=path_model, verbose=1,\n",
    "                             monitor='val_PPL',mode='min' ,save_best_only='True')\n",
    "# path_model = local_path + 'model/model.keras'\n",
    "# model.save(path_model)\n",
    "\n",
    "callback_lists=[tensorboard,checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 3677
    },
    "colab_type": "code",
    "id": "7rWihlHePo2Z",
    "outputId": "19ef2c40-5173-42d2-e4ff-d43ff273cd1d"
   },
   "outputs": [],
   "source": [
    "history = model.fit_generator(generator=gen_word_word(), \n",
    "                           steps_per_epoch=50, epochs=125,\n",
    "                           callbacks=callback_lists,\n",
    "                           validation_data=gen_word_word(dataset='valid'),\n",
    "                           validation_steps=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G2l21JdFPo3A"
   },
   "outputs": [],
   "source": [
    "logs = pd.DataFrame(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 301
    },
    "colab_type": "code",
    "id": "jQLqEZwRPo3M",
    "outputId": "9e0c5672-82b6-4fdb-8f11-739eb0007baa"
   },
   "outputs": [],
   "source": [
    "print(logs.columns)\n",
    "pylab.rcParams['figure.figsize'] = (13, 8)\n",
    "logs.loc[1:,['PPL','val_PPL']].plot() # start with 1 makes the figure prettier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kI9DyqjoPo3s"
   },
   "outputs": [],
   "source": [
    "# path_model = local_path + 'model/model.keras'\n",
    "# model.save(path_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "V_USEcjEPo3x"
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.models import load_model\n",
    "\n",
    "model_restore = load_model(path_model, custom_objects={'ACC':ACC,'PPL': PPL})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1129
    },
    "colab_type": "code",
    "id": "9iSl3szGPo37",
    "outputId": "150689c7-d3fb-4935-9184-dfc4ec6ef708",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "history = model_restore.fit_generator(generator=gen_word_word(), \n",
    "                           steps_per_epoch=50, epochs=3,\n",
    "                           callbacks=callback_lists,\n",
    "                           validation_data=gen_word_word(dataset='valid'),\n",
    "                           validation_steps=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 301
    },
    "colab_type": "code",
    "id": "WPNTJojePo4D",
    "outputId": "8b2ce958-73e2-4498-9f01-78d2f5d49a86"
   },
   "outputs": [],
   "source": [
    "logs = pd.DataFrame(history.history)\n",
    "print(logs.columns)\n",
    "pylab.rcParams['figure.figsize'] = (13, 8)\n",
    "logs.loc[:,['PPL','val_PPL']].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SY8V79vOPo4N"
   },
   "outputs": [],
   "source": [
    "def predict_seq(model, preSeq=None, genLen=seq_len, power=1):\n",
    "    \"\"\" Predict a sequence with length genLen.\n",
    "        arg:\n",
    "            model: Keras model used to predict.\n",
    "            preSeq: list. The leading sequence.\n",
    "            genLen: float or np.inf. If power is equal to np.inf, then an argmax will be used. \n",
    "            power: Probility power.\n",
    "    \"\"\"\n",
    "    preSeq = [word_to_id['<SS>']] if preSeq == None else [word_to_id['<SS>']] + preSeq   \n",
    "    pointer = len(preSeq) - 1\n",
    "    \n",
    "    for _ in range(genLen):\n",
    "        inputSeq = np.array([preSeq])\n",
    "        prob = model.predict(inputSeq)[0, pointer, :]\n",
    "        if power==np.inf:\n",
    "            pred = np.argmax(prob)\n",
    "        else:\n",
    "            prob = np.power(prob, power)\n",
    "            prob = prob / np.sum(prob)\n",
    "            pred = np.random.choice(range(voc_size), p=prob)\n",
    "        preSeq.append(pred)\n",
    "        pointer = pointer + 1\n",
    "\n",
    "    return preSeq, ' '.join([id_to_word[id] for id in preSeq])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, seq = predict_seq(model, power=1)\n",
    "seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Character aware model\n",
    "\n",
    "[Character-Aware Neural Language Models -- arxiv-1508.06615 -- AAAI 2016](https://arxiv.org/abs/1508.06615)\n",
    "\n",
    "[Ref: Github/jarfo/kchar](https://github.com/jarfo/kchar)\n",
    "\n",
    "\n",
    "![model](https://github.com/stikbuf/Language_Modeling/blob/master/Character%20aware.png?raw=true)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fKog3W-MPo4c"
   },
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### convert to text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_text = [id_to_word[idx] for idx in train_data]\n",
    "valid_data_text = [id_to_word[idx] for idx in valid_data]\n",
    "test_data_text = [id_to_word[idx] for idx in test_data]\n",
    "total_data_text = train_data_text + valid_data_text + test_data_text\n",
    "\n",
    "maxWordLen = max([len(word) for word in total_data_text])\n",
    "maxWordLen += 2 # Inclued Start and End character\n",
    "\n",
    "ds = pd.Series([len(word) for word in total_data_text])\n",
    "plt.figure(figsize=(10,5))\n",
    "ds.plot.hist(bins=range(1, maxWordLen))\n",
    "plt.title('word length distribution, max={0}, min={1}'.\n",
    "          format(ds.max(), ds.min()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### merge chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = []\n",
    "for word in total_data_text:\n",
    "    chars.extend(list(word))\n",
    "    \n",
    "ds = pd.Series(chars)\n",
    "plt.figure(figsize=(15,10))   \n",
    "matplotlib.rc('xtick', labelsize=20)\n",
    "matplotlib.rc('ytick', labelsize=15)\n",
    "ds.value_counts().plot.bar()\n",
    "plt.title('character distribution, total {0} characters(without \\'S\\' and \\'E\\')'.format(len(set(chars))))\n",
    "plt.show()\n",
    "\n",
    "chars = list(set(chars + ['S'] + ['E'] + [' ']))\n",
    "# 'S' for word leading char, 'E' for word ending char, space for padding\n",
    "id_to_chars = dict(enumerate(chars))\n",
    "chars_to_id = dict((v, k) for k,v in id_to_chars.items())\n",
    "num_chars = len(chars)\n",
    "\n",
    "print('number of chars:', num_chars, '\\n')\n",
    "print(chars, '\\n')\n",
    "print(id_to_chars, '\\n')\n",
    "print(chars_to_id, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_to_charId(wordId):\n",
    "    # Convert word to a string of word Ids\n",
    "    wordString = 'S' + id_to_word[wordId].center(maxWordLen - 2) + 'E'\n",
    "    return [chars_to_id[char] for char in wordString]\n",
    "\n",
    "def wordSeq_charSeq(bWordSeq):\n",
    "    batch, seqLen = bWordSeq.shape\n",
    "    bWordSeq = bWordSeq.ravel()\n",
    "    charSeq = np.array([word_to_charId(wordId) for wordId in bWordSeq])\n",
    "    return charSeq.reshape(batch, seqLen, -1)\n",
    "\n",
    "word_to_charId(word_to_id['the']) # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "from tensorflow.python.keras.utils import to_categorical \n",
    "\n",
    "def gen_char_word(batch_size=128, dataset='train'):\n",
    "    assert dataset in ['train', 'valid', 'test'], 'Dataset must be train or valid or test.'\n",
    "    \n",
    "    dic = {'train':train_data, 'valid':valid_data, 'test':test_data}\n",
    "    data = dic[dataset]\n",
    "    \n",
    "    while True:\n",
    "        rnd_idxs = list(range(len(data)-seq_len-1))\n",
    "        random.shuffle(rnd_idxs)\n",
    "        cnt = 0\n",
    "        while cnt < len(rnd_idxs) - batch_size :\n",
    "            X = np.array([[word_to_id['<SS>']] + data[i:i+seq_len] + [word_to_id['<EE>']]\n",
    "                          for i in rnd_idxs[cnt:cnt+batch_size]])\n",
    "            Y = X[:,1:]\n",
    "            X = X[:,:-1]\n",
    "            Y = to_categorical(Y)\n",
    "            X = wordSeq_charSeq(X) \n",
    "            #print(X.shape)\n",
    "            cnt += batch_size\n",
    "            yield X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(next(gen_char_word(batch_size=1, dataset='train'))[1][0][2].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## option"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Option():\n",
    "    def __init__(self):\n",
    "        self.batch_size = 20\n",
    "        self.seq_length = seq_len + 1\n",
    "        self.max_word_l = maxWordLen # Include Start and End character\n",
    "        self.char_vocab_size = num_chars\n",
    "        self.char_vec_size = 15\n",
    "        self.feature_maps = [50,100,150,200,200,200,200]\n",
    "        self.kernels = [1,2,3,4,5,6,7]\n",
    "        self.highway_layers = 2\n",
    "        self.num_lstm_layers = 2\n",
    "        self.rnn_size = 128\n",
    "        self.word_vocab_size = voc_size\n",
    "        self.dropout = 0.5\n",
    "        self.learing_rate = 1e-5\n",
    "        \n",
    "opt = Option()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN\n",
    "![CNN part](https://github.com/stikbuf/Language_Modeling/blob/master/Character%20aware-CNN.png?raw=true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.layers import Conv2D, MaxPooling2D, Concatenate, Reshape\n",
    "\n",
    "def CNN(seq_length, length, feature_maps, kernels, x):\n",
    "\n",
    "    concat_input = []\n",
    "    for feature_map, kernel in zip(feature_maps, kernels):\n",
    "        reduced_l = length - kernel + 1\n",
    "        conv = Conv2D(feature_map, (1, kernel), activation='tanh', data_format=\"channels_last\")(x)\n",
    "        maxp = MaxPooling2D((1, reduced_l), data_format=\"channels_last\")(conv)\n",
    "        concat_input.append(maxp)\n",
    "\n",
    "    x = Concatenate()(concat_input)\n",
    "    x = Reshape((seq_length, sum(feature_maps)))(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Highway Network  \n",
    "[Srivastava et al.](https://arxiv.org/abs/1505.00387)\n",
    "\n",
    "Input vector is $\\textbf{y}$, then layer output $\\textbf{z}$ is\n",
    "$$\\textbf{z = t} \\odot g(\\textbf{W}_H\\textbf{y}+\\textbf{b}_H) + \\textbf{(1 - t)} \\odot \\textbf{y}$$\n",
    "where \n",
    "$$\\textbf{t} = \\sigma(\\textbf{W}_T\\textbf{y}+\\textbf{b}_T)$$\n",
    "\n",
    "$\\textbf{t}$ is called the\n",
    "*transform gate*, and $(\\textbf{1}−\\textbf{t})$ is called the *carry gate*. \n",
    "Similar to the memory cells in LSTM networks, highway layers allow for training of deep networks by adaptively carrying some dimensions of the input directly to the output. By construction the dimensions of $\\textbf{y}$ and $\\textbf{z}$ have to match, and hence $\\textbf{W}_T$ and $\\textbf{W}_H$ are square matrices. **Basically, a highway layer is a dense layer with residual connection modulated by an adaptive gate.**\n",
    "\n",
    "A keras model is also a keras layer! So you can combine some keras layers to design your own layer. This is useful when combining with TimeDistributed wrapper. [See section 3 in this blog](https://keunwoochoi.wordpress.com/2016/11/18/for-beginners-writing-a-custom-keras-layer/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras import backend as K\n",
    "from tensorflow.python.keras.layers import Dense, Activation, Multiply, Add, Lambda, Input\n",
    "from tensorflow.python.keras.initializers import Constant\n",
    "from tensorflow.python.keras.models import Model\n",
    "\n",
    "class LambdaWithShape(Lambda):\n",
    "#     def __init__(self, function, **kwargs):\n",
    "#         super(LambdaWithShape, self).__init__(function, **kwargs)\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape\n",
    "\n",
    "def Highway(value, nLayers, activation='tanh', gateBias=-3):\n",
    "    dim = K.int_shape(value)[-1]\n",
    "    gateBiasInitalizer = Constant(gateBias)\n",
    "    for i in range(nLayers):\n",
    "        tGate = Dense(units=dim, bias_initializer=gateBiasInitalizer)(value)\n",
    "        tGate = Activation('sigmoid')(tGate)\n",
    "        #cGate = Lambda(lambda x: 1.0-x)(tGate) # WARNING:tensorflow:All custom layers should implement the `compute_output_shape`\n",
    "        cGate = LambdaWithShape(lambda x: 1.0-x)(tGate) # I do not specify output_shape\n",
    "        transformed = Dense(units=dim, bias_initializer=gateBiasInitalizer)(value)\n",
    "        transformed = Activation(activation)(value)\n",
    "        transformedGate = Multiply()([tGate, transformed])\n",
    "        identityGate = Multiply()([cGate, value])\n",
    "        value = Add()([transformedGate, identityGate])\n",
    "    return value\n",
    "\n",
    "inputs = Input((sum(opt.feature_maps),))\n",
    "HighwayLayer = Model(inputs=inputs, outputs=Highway(inputs, nLayers=opt.highway_layers))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.layers import Input, Embedding, GRU, Dropout, BatchNormalization, TimeDistributed\n",
    "#from tensorflow.python.keras.optimizers import SGD\n",
    "\n",
    "#chars = Input(batch_shape=(opt.batch_size, opt.seq_length, opt.max_word_l), name='chars')\n",
    "chars = Input(shape=(opt.seq_length, opt.max_word_l), name='chars') # will get a warning if you do not specify batch_shape\n",
    "chars_embedding = Embedding(opt.char_vocab_size, opt.char_vec_size, name='chars_embedding')(chars)\n",
    "cnn = CNN(opt.seq_length, opt.max_word_l, opt.feature_maps, opt.kernels, chars_embedding)\n",
    "x = cnn\n",
    "inputs = chars\n",
    "\n",
    "x = BatchNormalization()(x)\n",
    "\n",
    "x = TimeDistributed(HighwayLayer)(x)\n",
    "highway = x\n",
    "\n",
    "for l in range(opt.num_lstm_layers):\n",
    "    #x = GRU(opt.rnn_size, return_sequences=True, stateful=True)(x)\n",
    "    x = GRU(opt.rnn_size, return_sequences=True, stateful=False)(x)\n",
    "\n",
    "    if opt.dropout > 0:\n",
    "        x = Dropout(opt.dropout)(x)\n",
    "        \n",
    "output = Dense(opt.word_vocab_size, activation='softmax')(x)\n",
    "\n",
    "modelCAware = Model(inputs=inputs, outputs=output)\n",
    "modelCAware.summary()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelConvWordFeatureBeforeHighway = Model(inputs=inputs, outputs=cnn)\n",
    "modelConvWordFeatureAfterHighway = Model(inputs=inputs, outputs=highway)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perplexity\n",
    "def PPL(y_true, y_pred):\n",
    "    return tf.exp(tf.reduce_mean(tf.keras.backend.categorical_crossentropy(y_true, y_pred)))\n",
    "\n",
    "def ACC(y_true, y_pred):\n",
    "    ACC = tf.equal(tf.argmax(y_true, axis = 2), \n",
    "                   tf.argmax(y_pred, axis = 2))\n",
    "    ACC = tf.cast(ACC, tf.float32)\n",
    "\n",
    "    return tf.reduce_mean(ACC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.optimizers import RMSprop\n",
    "\n",
    "optimizer = RMSprop(lr=opt.learing_rate)\n",
    "modelCAware.compile(loss='categorical_crossentropy', optimizer='rmsprop',metrics=[ACC, PPL])  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tensorboard histograms\n",
    "Keras has a bug in TensorBoard visualization, see https://github.com/keras-team/keras/issues/3358  \n",
    "DO NOT set show_hist_gram=True  unless you want TensorBoard visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_hist_gram = True "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.callbacks import TensorBoard, ModelCheckpoint\n",
    "import os\n",
    "if not os.path.exists(local_path + 'model/'):\n",
    "    os.mkdir(local_path + 'model/')\n",
    "\n",
    "path_model = local_path + 'model/modelAware.keras'\n",
    "if show_hist_gram:\n",
    "    tensorboard = TensorBoard(log_dir='log', histogram_freq=1, write_grads=True)\n",
    "else:\n",
    "    tensorboard = TensorBoard(log_dir='log')\n",
    "checkpoint = ModelCheckpoint(filepath=path_model, verbose=1,\n",
    "                             monitor='val_PPL',mode='min' ,save_best_only='True')\n",
    "# path_model = local_path + 'model/model.keras'\n",
    "# model.save(path_model)\n",
    "\n",
    "callback_lists=[tensorboard,checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if show_hist_gram:\n",
    "    history = modelCAware.fit_generator(generator=gen_char_word(batch_size=opt.batch_size), \n",
    "                           steps_per_epoch=50, epochs=5,\n",
    "                           callbacks=callback_lists, \n",
    "                           #validation_data=gen_char_word(batch_size=opt.batch_size, dataset='valid'),#ValueError: If printing histograms, validation_data must be provided, and cannot be a generator.\n",
    "                           validation_data=next(gen_char_word(batch_size=(len(valid_data)-seq_len-2)//100, dataset='valid')),  # //100 to avoid memory error.        \n",
    "                           validation_steps=None) \n",
    "else:\n",
    "    history = modelCAware.fit_generator(generator=gen_char_word(batch_size=opt.batch_size), \n",
    "                           steps_per_epoch=50, epochs=5,\n",
    "                           callbacks=callback_lists, \n",
    "                           validation_data=gen_char_word(batch_size=opt.batch_size, dataset='valid'),#ValueError: If printing histograms, validation_data must be provided, and cannot be a generator.\n",
    "                           #validation_data=next(gen_char_word(batch_size=(len(valid_data)-seq_len-2)//100, dataset='valid')),  # //10 to avoid memory error. DO NOT use this line unless you want TensorBoard visualization       \n",
    "                           validation_steps=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logs = pd.DataFrame(history.history)\n",
    "print(logs.columns)\n",
    "pylab.rcParams['figure.figsize'] = (13, 8)\n",
    "logs.loc[1:,['PPL','val_PPL']].plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word feature analysis\n",
    "The convolution and the highway network can be viewed as a word feature extractor. Let's establish some intuition by the following experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractWordFeature(words, extcModel=modelConvWordFeatureAfterHighway):\n",
    "    \"\"\"\n",
    "    words: List of word text.\n",
    "    extcModel: Extractor model.\n",
    "    \n",
    "    returns: Pandas dataframe. Index is the word, corresponding to the feature vector.\n",
    "    \"\"\"\n",
    "    \n",
    "    padWord = lambda word: 'S' + word.lower().center(opt.max_word_l - 2) + 'E' # pad a single word\n",
    "    wordsPadedCroped = [padWord(word[:opt.max_word_l-2]) for word in words] # cut input word if it is too long\n",
    "    #print(wordsPadedCroped)\n",
    "    wordsPadedCroped = [[chars_to_id[char] for char in word] for word in wordsPadedCroped] # convert to char index\n",
    "    #print(wordsPadedCroped)\n",
    "    \n",
    "    # split into batches, list of tuples\n",
    "    batches = []\n",
    "    while wordsPadedCroped != []:\n",
    "        if len(wordsPadedCroped)>opt.seq_length:\n",
    "            batches.append((np.array(wordsPadedCroped[:opt.seq_length]), opt.seq_length))\n",
    "            wordsPadedCroped = wordsPadedCroped[opt.seq_length:]\n",
    "        else:\n",
    "            wLast = wordsPadedCroped + [[chars_to_id[' ']]*opt.max_word_l]*(opt.seq_length-len(wordsPadedCroped))         \n",
    "            batches.append((np.array(wLast), len(wordsPadedCroped)))\n",
    "            wordsPadedCroped = []   \n",
    "    \n",
    "    features = []\n",
    "    for batch in batches:\n",
    "        data = batch[0]\n",
    "        validNum = batch[1]\n",
    "        features.append(extcModel.predict(np.expand_dims(data,0))[0,:validNum,:])\n",
    "    \n",
    "    features = np.vstack(features)\n",
    "    \n",
    "    # return a dataframe\n",
    "    features = pd.DataFrame(data=features, index=words)\n",
    "    features.index.name = 'featVecs'\n",
    "    features.columns.name = 'vecDims'\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampleWordList = ['look','looks','looked','looking','lok','looooooook',\n",
    "                  'lk','loop','lock','locked','cook','see','observation',\n",
    "                  'hear','run','reading','news','book','computer',\n",
    "                  'programming','python','java','lisp','c#','matlab','jupyter']\n",
    "vocWordList = list(word_id.index)\n",
    "print(vocWordList[:5], '......', vocWordList[-4:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "def sortedWordsByDistance(queryWord, Words, metric='cosine', \n",
    "                          extcModel=modelConvWordFeatureBeforeHighway):\n",
    "    \"\"\"\n",
    "    queryWord: Single query word\n",
    "    Words: Words to compare\n",
    "    metric: metrics -- 'cosine',euclidean','correlation',...\n",
    "    \"\"\"\n",
    "    queryWordFeat = extractWordFeature([queryWord], extcModel=extcModel)\n",
    "    wordFeats = extractWordFeature(Words, extcModel=extcModel) \n",
    "    \n",
    "    dis = pd.Series(cdist(queryWordFeat, wordFeats, metric=metric)[0])\n",
    "    dis.index = Words\n",
    "    dis = dis.sort_values(ascending=True)\n",
    "    return dis\n",
    "    \n",
    "    \n",
    "sortedDis = sortedWordsByDistance('look', sampleWordList)\n",
    "sortedDis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smpFeatures = extractWordFeature(sampleWordList, extcModel=modelConvWordFeatureAfterHighway)\n",
    "smpFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "def featureVis(feautres, usePCA=True):\n",
    "    \"\"\"\n",
    "    features: A pandas dataframe. Index should be words, values should be word features.\n",
    "    \"\"\"\n",
    "    wordList = feautres.index\n",
    "    featTransed = feautres.values\n",
    "    if usePCA:\n",
    "        featTransed = PCA(n_components=len(feautres.columns)//7).fit_transform(featTransed)\n",
    "    featTransed = TSNE(n_components=2).fit_transform(featTransed)\n",
    "    featTransed = pd.DataFrame(featTransed, index=wordList)\n",
    "    featTransed.index.name = 'featVecs'\n",
    "    featTransed.columns.name = 'vecDims'\n",
    "\n",
    "    pylab.rcParams['figure.figsize'] = (13, 8)\n",
    "    axes = featTransed.plot.scatter(x=0, y=1)\n",
    "    for txt in wordList:\n",
    "        axes.annotate(txt, (featTransed.loc[txt,0],featTransed.loc[txt,1]))\n",
    "        \n",
    "featureVis(smpFeatures, usePCA=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocFeatures = extractWordFeature(vocWordList, extcModel=modelConvWordFeatureAfterHighway)\n",
    "vocFeatures.head(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "sample = vocFeatures.sample(200)\n",
    "featureVis(sample, usePCA=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gated CNN model\n",
    "\n",
    "[Language Modeling with Gated Convolutional Networks -- arxiv-1612.08083 -- Facebook AI Research](https://arxiv.org/abs/1612.08083)\n",
    "![Gated CNN model](https://github.com/stikbuf/Language_Modeling/blob/master/Gated%20CNN.png?raw=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data generator\n",
    "\n",
    "Same as RNN baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "from tensorflow.python.keras.utils import to_categorical \n",
    "\n",
    "def gen_word_word(batch_size=128, dataset='train'):\n",
    "    assert dataset in ['train', 'valid', 'test'], 'Dataset must be train or valid or test.'\n",
    "    \n",
    "    dic = {'train':train_data, 'valid':valid_data, 'test':test_data}\n",
    "    data = dic[dataset]\n",
    "    \n",
    "    while True:\n",
    "        rnd_idxs = list(range(len(data)-seq_len-1))\n",
    "        random.shuffle(rnd_idxs)\n",
    "        cnt = 0\n",
    "        while cnt < len(rnd_idxs) - batch_size :\n",
    "            X = np.array([[word_to_id['<SS>']] + data[i:i+seq_len] + [word_to_id['<EE>']]\n",
    "                          for i in rnd_idxs[cnt:cnt+batch_size]])\n",
    "            Y = X[:,1:]\n",
    "            X = X[:,:-1]\n",
    "            Y = to_categorical(Y)\n",
    "            #print(X.shape)\n",
    "            cnt += batch_size\n",
    "            yield X, Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model\n",
    "![model configuration](https://github.com/stikbuf/Language_Modeling/blob/dev/figures/gCNNConfig.png?raw=true)\n",
    "\n",
    "I call:  \n",
    "\"(4, 1268)\" a unit  \n",
    "\"[(4, 1268), (4, 1268)]\" a block  \n",
    "\"[(4, 1268), (4, 1268)] * 12\" a chunk  \n",
    "A model is made by chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.layers import Conv1D, Multiply, Add, Input, Dense, Embedding\n",
    "from tensorflow.python.keras.models import Model\n",
    "from tensorflow.python.keras import backend as K\n",
    "\n",
    "def gatedCNNUnit(kernel_size=3, filters=1024, input_shape=None):\n",
    "    #print(input_shape)\n",
    "    inputs = Input(shape=input_shape)\n",
    "    conv = Conv1D(filters=filters, kernel_size=kernel_size,\n",
    "                  strides=1, padding='same')(inputs)\n",
    "    gated = Conv1D(filters=filters, kernel_size=kernel_size, \n",
    "                   strides=1, padding='same', activation='sigmoid')(inputs)\n",
    "    value = Multiply()([conv, gated])\n",
    "    print(K.int_shape(value)[1:])\n",
    "    return Model(inputs=inputs, outputs=value)\n",
    "    \n",
    "    \n",
    "def gatedCNNChunk(chunk, input_shape):\n",
    "    origin = Input(shape=input_shape)\n",
    "    inputs = origin\n",
    "    for block in chunk:\n",
    "        for unit in block:\n",
    "            kernel_size, filters = unit\n",
    "            x = gatedCNNUnit(kernel_size=kernel_size, filters=filters, input_shape=K.int_shape(inputs)[1:])(inputs)\n",
    "        if K.int_shape(inputs)[-1] != K.int_shape(x)[-1]:\n",
    "            inputs = Dense( K.int_shape(x)[-1])(inputs)\n",
    "        x = Add()([inputs, x])\n",
    "        inputs = x\n",
    "    return Model(inputs=origin, outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([[(4, 900)]],\n",
       " [[(4, 900)],\n",
       "  [(4, 900)],\n",
       "  [(4, 900)],\n",
       "  [(4, 900)],\n",
       "  [(4, 900)],\n",
       "  [(4, 900)],\n",
       "  [(4, 900)]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# embedding_size=128 in the paper\n",
    "GCNN_13 = [ [(4, 1268)] ]*1 ,\\\n",
    "          [ [(4,1268), (4,1268)] ]*12 \n",
    "    \n",
    "GCNN_14B = [ [(5, 512)] ]*1 ,\\\n",
    "           [ [(1,128), (5,128), (1,512)] ]*3 ,\\\n",
    "           [ [(1,512), (5,512), (1,1024)] ]*3 ,\\\n",
    "           [ [(1,1024), (5,1024), (1,2048)] ]*6 ,\\\n",
    "            [ [(1,1024), (5,1024), (1,4096)] ]*1 \n",
    "            \n",
    "GCNN_9 = [ [(4, 807)] ]*1 ,\\\n",
    "          [ [(4,807), (4,807)] ]*4  \n",
    "    \n",
    "GCNN_8B = [ [(1, 512)] ]*1 ,\\\n",
    "           [ [(1,128), (5,128), (1,512)] ]*3 ,\\\n",
    "           [ [(1,256), (5,256), (1,512)] ]*3 ,\\\n",
    "           [ [(1,1024), (1,1024), (1,2048)] ]*1 \n",
    "\n",
    "# embedding_size=208 in the paper\n",
    "GCNN_8 = [ [(4, 900)] ]*1 ,\\\n",
    "           [ [(4,900)] ]*7\n",
    "\n",
    "GCNN_14 = [ [(6, 850)] ]*3 ,\\\n",
    "           [ [(1,850)] ]*1 ,\\\n",
    "           [ [(5,850)] ]*4 ,\\\n",
    "           [ [(1,850)] ]*1 ,\\\n",
    "            [ [(4,850)] ]*3 ,\\\n",
    "            [ [(4,1024)] ]*1 ,\\\n",
    "            [ [(4,2048)] ]*1  \n",
    "    \n",
    "modelParam = GCNN_8\n",
    "modelParam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 900)\n",
      "use dense\n",
      "(None, 900)\n",
      "(None, 900)\n",
      "(None, 900)\n",
      "(None, 900)\n",
      "(None, 900)\n",
      "(None, 900)\n",
      "(None, 900)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_235 (InputLayer)       (None, None)              0         \n",
      "_________________________________________________________________\n",
      "embedding_7 (Embedding)      (None, None, 128)         1280256   \n",
      "_________________________________________________________________\n",
      "model_236 (Model)            (None, None, 900)         1039500   \n",
      "_________________________________________________________________\n",
      "model_244 (Model)            (None, None, 900)         45372600  \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, None, 10002)       9011802   \n",
      "=================================================================\n",
      "Total params: 56,704,158\n",
      "Trainable params: 56,704,158\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "embedding_size = 128\n",
    "\n",
    "inputs = Input(shape=(None,))\n",
    "x = Embedding(input_dim=voc_size,\n",
    "              output_dim=embedding_size)(inputs)\n",
    "for chunk in modelParam:\n",
    "    x = gatedCNNChunk(chunk, K.int_shape(x)[1:])(x)\n",
    "\n",
    "x = Dense(voc_size, activation='softmax')(x)\n",
    "gCNNModel = Model(inputs=inputs, outputs=x)\n",
    "gCNNModel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perplexity\n",
    "def PPL(y_true, y_pred):\n",
    "    return tf.exp(tf.reduce_mean(tf.keras.backend.categorical_crossentropy(y_true, y_pred)))\n",
    "\n",
    "def ACC(y_true, y_pred):\n",
    "    ACC = tf.equal(tf.argmax(y_true, axis = 2), \n",
    "                   tf.argmax(y_pred, axis = 2))\n",
    "    ACC = tf.cast(ACC, tf.float32)\n",
    "\n",
    "    return tf.reduce_mean(ACC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.optimizers import RMSprop\n",
    "\n",
    "optimizer = RMSprop(lr=1e-6)\n",
    "gCNNModel.compile(optimizer=optimizer,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=[ACC, PPL])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.callbacks import TensorBoard, ModelCheckpoint\n",
    "import os\n",
    "if not os.path.exists(local_path + 'model/'):\n",
    "    os.mkdir(local_path + 'model/')\n",
    "\n",
    "path_model = local_path + 'model/model.keras'    \n",
    "tensorboard = TensorBoard(log_dir='log')\n",
    "checkpoint = ModelCheckpoint(filepath=path_model, verbose=1,\n",
    "                             monitor='val_PPL',mode='min' ,save_best_only='True')\n",
    "# path_model = local_path + 'model/model.keras'\n",
    "# model.save(path_model)\n",
    "\n",
    "callback_lists=[tensorboard,checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/125\n",
      "49/50 [============================>.] - ETA: 0s - loss: 8.5283 - ACC: 0.0634 - PPL: 5718.8555\n",
      "Epoch 00001: val_PPL improved from inf to 2463.87805, saving model to ./model/model.keras\n",
      "50/50 [==============================] - 43s 861ms/step - loss: 8.5131 - ACC: 0.0647 - PPL: 5651.6442 - val_loss: 7.8089 - val_ACC: 0.0996 - val_PPL: 2463.8781\n",
      "Epoch 2/125\n",
      "49/50 [============================>.] - ETA: 0s - loss: 7.4296 - ACC: 0.1177 - PPL: 1729.1289\n",
      "Epoch 00002: val_PPL improved from 2463.87805 to 1278.11442, saving model to ./model/model.keras\n",
      "50/50 [==============================] - 43s 852ms/step - loss: 7.4280 - ACC: 0.1179 - PPL: 1725.6833 - val_loss: 7.1521 - val_ACC: 0.1433 - val_PPL: 1278.1144\n",
      "Epoch 3/125\n",
      "49/50 [============================>.] - ETA: 0s - loss: 7.0025 - ACC: 0.1612 - PPL: 1119.8093\n",
      "Epoch 00003: val_PPL improved from 1278.11442 to 897.95807, saving model to ./model/model.keras\n",
      "50/50 [==============================] - 45s 902ms/step - loss: 7.0046 - ACC: 0.1612 - PPL: 1121.8604 - val_loss: 6.7985 - val_ACC: 0.1813 - val_PPL: 897.9581\n",
      "Epoch 4/125\n",
      "49/50 [============================>.] - ETA: 0s - loss: 6.6663 - ACC: 0.1916 - PPL: 795.8430\n",
      "Epoch 00004: val_PPL improved from 897.95807 to 685.73383, saving model to ./model/model.keras\n",
      "50/50 [==============================] - 45s 890ms/step - loss: 6.6657 - ACC: 0.1917 - PPL: 795.1696 - val_loss: 6.5292 - val_ACC: 0.2003 - val_PPL: 685.7338\n",
      "Epoch 5/125\n",
      "49/50 [============================>.] - ETA: 0s - loss: 6.4051 - ACC: 0.2140 - PPL: 616.1894\n",
      "Epoch 00005: val_PPL improved from 685.73383 to 538.63886, saving model to ./model/model.keras\n",
      "50/50 [==============================] - 42s 835ms/step - loss: 6.4040 - ACC: 0.2142 - PPL: 615.3115 - val_loss: 6.2877 - val_ACC: 0.2277 - val_PPL: 538.6389\n",
      "Epoch 6/125\n",
      "49/50 [============================>.] - ETA: 0s - loss: 6.2366 - ACC: 0.2367 - PPL: 521.4031\n",
      "Epoch 00006: val_PPL improved from 538.63886 to 458.74425, saving model to ./model/model.keras\n",
      "50/50 [==============================] - 43s 869ms/step - loss: 6.2376 - ACC: 0.2363 - PPL: 521.7635 - val_loss: 6.1266 - val_ACC: 0.2503 - val_PPL: 458.7443\n",
      "Epoch 7/125\n",
      "49/50 [============================>.] - ETA: 0s - loss: 6.1094 - ACC: 0.2545 - PPL: 455.8179\n",
      "Epoch 00007: val_PPL improved from 458.74425 to 399.10582, saving model to ./model/model.keras\n",
      "50/50 [==============================] - 44s 887ms/step - loss: 6.1109 - ACC: 0.2545 - PPL: 456.4253 - val_loss: 5.9881 - val_ACC: 0.2667 - val_PPL: 399.1058\n",
      "Epoch 8/125\n",
      "49/50 [============================>.] - ETA: 0s - loss: 5.9716 - ACC: 0.2737 - PPL: 398.1089\n",
      "Epoch 00008: val_PPL improved from 399.10582 to 347.18307, saving model to ./model/model.keras\n",
      "50/50 [==============================] - 46s 917ms/step - loss: 5.9670 - ACC: 0.2741 - PPL: 396.3958 - val_loss: 5.8480 - val_ACC: 0.2846 - val_PPL: 347.1831\n",
      "Epoch 9/125\n",
      "49/50 [============================>.] - ETA: 0s - loss: 5.8310 - ACC: 0.2910 - PPL: 344.2204\n",
      "Epoch 00009: val_PPL improved from 347.18307 to 306.85946, saving model to ./model/model.keras\n",
      "50/50 [==============================] - 51s 1s/step - loss: 5.8283 - ACC: 0.2911 - PPL: 343.2686 - val_loss: 5.7247 - val_ACC: 0.2998 - val_PPL: 306.8595\n",
      "Epoch 10/125\n",
      "49/50 [============================>.] - ETA: 0s - loss: 5.6947 - ACC: 0.3064 - PPL: 301.7673\n",
      "Epoch 00010: val_PPL improved from 306.85946 to 278.96054, saving model to ./model/model.keras\n",
      "50/50 [==============================] - 45s 909ms/step - loss: 5.6986 - ACC: 0.3064 - PPL: 302.9510 - val_loss: 5.6291 - val_ACC: 0.3133 - val_PPL: 278.9605\n",
      "Epoch 11/125\n",
      "49/50 [============================>.] - ETA: 0s - loss: 5.5699 - ACC: 0.3210 - PPL: 267.7437\n",
      "Epoch 00011: val_PPL improved from 278.96054 to 251.41006, saving model to ./model/model.keras\n",
      "50/50 [==============================] - 52s 1s/step - loss: 5.5708 - ACC: 0.3208 - PPL: 267.8654 - val_loss: 5.5253 - val_ACC: 0.3215 - val_PPL: 251.4101\n",
      "Epoch 12/125\n",
      "49/50 [============================>.] - ETA: 0s - loss: 5.5071 - ACC: 0.3238 - PPL: 249.9800\n",
      "Epoch 00012: val_PPL improved from 251.41006 to 232.62026, saving model to ./model/model.keras\n",
      "50/50 [==============================] - 45s 898ms/step - loss: 5.5034 - ACC: 0.3244 - PPL: 249.0779 - val_loss: 5.4466 - val_ACC: 0.3270 - val_PPL: 232.6203\n",
      "Epoch 13/125\n",
      "49/50 [============================>.] - ETA: 0s - loss: 5.4325 - ACC: 0.3364 - PPL: 232.5437\n",
      "Epoch 00013: val_PPL improved from 232.62026 to 212.29694, saving model to ./model/model.keras\n",
      "50/50 [==============================] - 52s 1s/step - loss: 5.4359 - ACC: 0.3359 - PPL: 233.3130 - val_loss: 5.3549 - val_ACC: 0.3364 - val_PPL: 212.2969\n",
      "Epoch 14/125\n",
      "49/50 [============================>.] - ETA: 0s - loss: 5.3438 - ACC: 0.3448 - PPL: 213.4653\n",
      "Epoch 00014: val_PPL improved from 212.29694 to 197.72469, saving model to ./model/model.keras\n",
      "50/50 [==============================] - 47s 943ms/step - loss: 5.3450 - ACC: 0.3445 - PPL: 213.6443 - val_loss: 5.2847 - val_ACC: 0.3500 - val_PPL: 197.7247\n",
      "Epoch 15/125\n",
      "49/50 [============================>.] - ETA: 0s - loss: 5.2508 - ACC: 0.3547 - PPL: 194.0353\n",
      "Epoch 00015: val_PPL improved from 197.72469 to 181.82112, saving model to ./model/model.keras\n",
      "50/50 [==============================] - 47s 941ms/step - loss: 5.2516 - ACC: 0.3547 - PPL: 194.1188 - val_loss: 5.2004 - val_ACC: 0.3579 - val_PPL: 181.8211\n",
      "Epoch 16/125\n",
      "49/50 [============================>.] - ETA: 0s - loss: 5.1772 - ACC: 0.3645 - PPL: 180.5045\n",
      "Epoch 00016: val_PPL improved from 181.82112 to 173.23377, saving model to ./model/model.keras\n",
      "50/50 [==============================] - 51s 1s/step - loss: 5.1816 - ACC: 0.3644 - PPL: 181.2968 - val_loss: 5.1532 - val_ACC: 0.3675 - val_PPL: 173.2338\n",
      "Epoch 17/125\n",
      "49/50 [============================>.] - ETA: 0s - loss: 5.0924 - ACC: 0.3745 - PPL: 165.3913\n",
      "Epoch 00017: val_PPL improved from 173.23377 to 163.13553, saving model to ./model/model.keras\n",
      "50/50 [==============================] - 46s 925ms/step - loss: 5.0960 - ACC: 0.3743 - PPL: 165.9876 - val_loss: 5.0930 - val_ACC: 0.3756 - val_PPL: 163.1355\n",
      "Epoch 18/125\n",
      "49/50 [============================>.] - ETA: 0s - loss: 5.0689 - ACC: 0.3757 - PPL: 161.4449\n",
      "Epoch 00018: val_PPL improved from 163.13553 to 154.17669, saving model to ./model/model.keras\n",
      "50/50 [==============================] - 54s 1s/step - loss: 5.0689 - ACC: 0.3761 - PPL: 161.4021 - val_loss: 5.0357 - val_ACC: 0.3802 - val_PPL: 154.1767\n",
      "Epoch 19/125\n",
      "49/50 [============================>.] - ETA: 0s - loss: 5.0351 - ACC: 0.3821 - PPL: 156.2985\n",
      "Epoch 00019: val_PPL improved from 154.17669 to 148.74208, saving model to ./model/model.keras\n",
      "50/50 [==============================] - 48s 957ms/step - loss: 5.0291 - ACC: 0.3829 - PPL: 155.4511 - val_loss: 4.9996 - val_ACC: 0.3882 - val_PPL: 148.7421\n",
      "Epoch 20/125\n",
      "49/50 [============================>.] - ETA: 0s - loss: 4.9700 - ACC: 0.3931 - PPL: 146.4949\n",
      "Epoch 00020: val_PPL improved from 148.74208 to 140.33753, saving model to ./model/model.keras\n",
      "50/50 [==============================] - 48s 960ms/step - loss: 4.9598 - ACC: 0.3937 - PPL: 145.2991 - val_loss: 4.9425 - val_ACC: 0.3952 - val_PPL: 140.3375\n",
      "Epoch 21/125\n",
      "49/50 [============================>.] - ETA: 0s - loss: 4.9305 - ACC: 0.3999 - PPL: 141.5259\n",
      "Epoch 00021: val_PPL improved from 140.33753 to 129.40159, saving model to ./model/model.keras\n",
      "50/50 [==============================] - 48s 966ms/step - loss: 4.9291 - ACC: 0.4000 - PPL: 141.2708 - val_loss: 4.8606 - val_ACC: 0.4088 - val_PPL: 129.4016\n",
      "Epoch 22/125\n",
      "49/50 [============================>.] - ETA: 0s - loss: 4.8884 - ACC: 0.4064 - PPL: 135.7049\n",
      "Epoch 00022: val_PPL improved from 129.40159 to 126.84750, saving model to ./model/model.keras\n",
      "50/50 [==============================] - 54s 1s/step - loss: 4.8864 - ACC: 0.4067 - PPL: 135.3899 - val_loss: 4.8415 - val_ACC: 0.4088 - val_PPL: 126.8475\n",
      "Epoch 23/125\n",
      "49/50 [============================>.] - ETA: 0s - loss: 4.7931 - ACC: 0.4172 - PPL: 122.9504\n",
      "Epoch 00023: val_PPL improved from 126.84750 to 117.07078, saving model to ./model/model.keras\n",
      "50/50 [==============================] - 46s 912ms/step - loss: 4.7902 - ACC: 0.4176 - PPL: 122.5765 - val_loss: 4.7594 - val_ACC: 0.4198 - val_PPL: 117.0708\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/125\n",
      "49/50 [============================>.] - ETA: 0s - loss: 4.7359 - ACC: 0.4251 - PPL: 115.7530\n",
      "Epoch 00024: val_PPL did not improve\n",
      "50/50 [==============================] - 37s 740ms/step - loss: 4.7401 - ACC: 0.4247 - PPL: 116.2560 - val_loss: 4.7643 - val_ACC: 0.4225 - val_PPL: 117.4359\n",
      "Epoch 25/125\n",
      "49/50 [============================>.] - ETA: 0s - loss: 4.7548 - ACC: 0.4252 - PPL: 117.4271\n",
      "Epoch 00025: val_PPL improved from 117.07078 to 111.23944, saving model to ./model/model.keras\n",
      "50/50 [==============================] - 50s 997ms/step - loss: 4.7590 - ACC: 0.4245 - PPL: 117.9478 - val_loss: 4.7100 - val_ACC: 0.4265 - val_PPL: 111.2394\n",
      "Epoch 26/125\n",
      "49/50 [============================>.] - ETA: 0s - loss: 4.7138 - ACC: 0.4276 - PPL: 113.3617\n",
      "Epoch 00026: val_PPL improved from 111.23944 to 104.42308, saving model to ./model/model.keras\n",
      "50/50 [==============================] - 49s 982ms/step - loss: 4.7109 - ACC: 0.4280 - PPL: 113.0159 - val_loss: 4.6457 - val_ACC: 0.4360 - val_PPL: 104.4231\n",
      "Epoch 27/125\n",
      "49/50 [============================>.] - ETA: 0s - loss: 4.6211 - ACC: 0.4415 - PPL: 103.0005\n",
      "Epoch 00027: val_PPL improved from 104.42308 to 101.80578, saving model to ./model/model.keras\n",
      "50/50 [==============================] - 48s 952ms/step - loss: 4.6134 - ACC: 0.4425 - PPL: 102.3206 - val_loss: 4.6216 - val_ACC: 0.4433 - val_PPL: 101.8058\n",
      "Epoch 28/125\n",
      "49/50 [============================>.] - ETA: 0s - loss: 4.5990 - ACC: 0.4458 - PPL: 101.4837\n",
      "Epoch 00028: val_PPL did not improve\n",
      "50/50 [==============================] - 37s 746ms/step - loss: 4.6001 - ACC: 0.4457 - PPL: 101.5558 - val_loss: 4.6230 - val_ACC: 0.4449 - val_PPL: 102.0177\n",
      "Epoch 29/125\n",
      "49/50 [============================>.] - ETA: 0s - loss: 4.5341 - ACC: 0.4515 - PPL: 95.4873\n",
      "Epoch 00029: val_PPL improved from 101.80578 to 95.76326, saving model to ./model/model.keras\n",
      "50/50 [==============================] - 54s 1s/step - loss: 4.5364 - ACC: 0.4515 - PPL: 95.6655 - val_loss: 4.5588 - val_ACC: 0.4539 - val_PPL: 95.7633\n",
      "Epoch 30/125\n",
      "49/50 [============================>.] - ETA: 0s - loss: 4.4918 - ACC: 0.4578 - PPL: 90.6322\n",
      "Epoch 00030: val_PPL improved from 95.76326 to 89.68968, saving model to ./model/model.keras\n",
      "50/50 [==============================] - 50s 1s/step - loss: 4.4852 - ACC: 0.4588 - PPL: 90.1045 - val_loss: 4.4948 - val_ACC: 0.4625 - val_PPL: 89.6897\n",
      "Epoch 31/125\n",
      "49/50 [============================>.] - ETA: 0s - loss: 4.4730 - ACC: 0.4654 - PPL: 90.1533\n",
      "Epoch 00031: val_PPL improved from 89.68968 to 88.70796, saving model to ./model/model.keras\n",
      "50/50 [==============================] - 53s 1s/step - loss: 4.4788 - ACC: 0.4650 - PPL: 90.6891 - val_loss: 4.4838 - val_ACC: 0.4637 - val_PPL: 88.7080\n",
      "Epoch 32/125\n",
      "49/50 [============================>.] - ETA: 0s - loss: 4.4726 - ACC: 0.4622 - PPL: 88.7180\n",
      "Epoch 00032: val_PPL improved from 88.70796 to 85.36748, saving model to ./model/model.keras\n",
      "50/50 [==============================] - 49s 973ms/step - loss: 4.4739 - ACC: 0.4620 - PPL: 88.8159 - val_loss: 4.4450 - val_ACC: 0.4698 - val_PPL: 85.3675\n",
      "Epoch 33/125\n",
      "49/50 [============================>.] - ETA: 0s - loss: 4.4302 - ACC: 0.4699 - PPL: 86.3805\n",
      "Epoch 00033: val_PPL improved from 85.36748 to 82.86089, saving model to ./model/model.keras\n",
      "50/50 [==============================] - 52s 1s/step - loss: 4.4312 - ACC: 0.4698 - PPL: 86.4178 - val_loss: 4.4139 - val_ACC: 0.4715 - val_PPL: 82.8609\n",
      "Epoch 34/125\n",
      "49/50 [============================>.] - ETA: 0s - loss: 4.3868 - ACC: 0.4736 - PPL: 81.8955\n",
      "Epoch 00034: val_PPL improved from 82.86089 to 78.88092, saving model to ./model/model.keras\n",
      "50/50 [==============================] - 50s 995ms/step - loss: 4.3876 - ACC: 0.4739 - PPL: 81.9305 - val_loss: 4.3655 - val_ACC: 0.4796 - val_PPL: 78.8809\n",
      "Epoch 35/125\n",
      "49/50 [============================>.] - ETA: 0s - loss: 4.3359 - ACC: 0.4812 - PPL: 78.0158\n",
      "Epoch 00035: val_PPL improved from 78.88092 to 76.27766, saving model to ./model/model.keras\n",
      "50/50 [==============================] - 48s 960ms/step - loss: 4.3322 - ACC: 0.4815 - PPL: 77.7248 - val_loss: 4.3326 - val_ACC: 0.4826 - val_PPL: 76.2777\n",
      "Epoch 36/125\n",
      "49/50 [============================>.] - ETA: 0s - loss: 4.3216 - ACC: 0.4804 - PPL: 76.3447\n",
      "Epoch 00036: val_PPL improved from 76.27766 to 75.81263, saving model to ./model/model.keras\n",
      "50/50 [==============================] - 56s 1s/step - loss: 4.3274 - ACC: 0.4796 - PPL: 76.8318 - val_loss: 4.3252 - val_ACC: 0.4859 - val_PPL: 75.8126\n",
      "Epoch 37/125\n",
      "49/50 [============================>.] - ETA: 0s - loss: 4.3365 - ACC: 0.4809 - PPL: 77.8704\n",
      "Epoch 00037: val_PPL improved from 75.81263 to 73.82261, saving model to ./model/model.keras\n",
      "50/50 [==============================] - 46s 914ms/step - loss: 4.3359 - ACC: 0.4811 - PPL: 77.7996 - val_loss: 4.2991 - val_ACC: 0.4876 - val_PPL: 73.8226\n",
      "Epoch 38/125\n",
      "49/50 [============================>.] - ETA: 0s - loss: 4.2428 - ACC: 0.4932 - PPL: 70.8968\n",
      "Epoch 00038: val_PPL improved from 73.82261 to 71.20055, saving model to ./model/model.keras\n",
      "50/50 [==============================] - 54s 1s/step - loss: 4.2425 - ACC: 0.4932 - PPL: 70.8509 - val_loss: 4.2630 - val_ACC: 0.4904 - val_PPL: 71.2005\n",
      "Epoch 39/125\n",
      "49/50 [============================>.] - ETA: 0s - loss: 4.2683 - ACC: 0.4906 - PPL: 72.7166\n",
      "Epoch 00039: val_PPL improved from 71.20055 to 68.11071, saving model to ./model/model.keras\n",
      "50/50 [==============================] - 49s 975ms/step - loss: 4.2672 - ACC: 0.4903 - PPL: 72.6109 - val_loss: 4.2179 - val_ACC: 0.4970 - val_PPL: 68.1107\n",
      "Epoch 40/125\n",
      "49/50 [============================>.] - ETA: 0s - loss: 4.2366 - ACC: 0.4953 - PPL: 70.1599\n",
      "Epoch 00040: val_PPL improved from 68.11071 to 65.92331, saving model to ./model/model.keras\n",
      "50/50 [==============================] - 55s 1s/step - loss: 4.2412 - ACC: 0.4946 - PPL: 70.4930 - val_loss: 4.1862 - val_ACC: 0.5002 - val_PPL: 65.9233\n",
      "Epoch 41/125\n",
      "49/50 [============================>.] - ETA: 0s - loss: 4.1728 - ACC: 0.4985 - PPL: 66.5223\n",
      "Epoch 00041: val_PPL improved from 65.92331 to 65.46428, saving model to ./model/model.keras\n",
      "50/50 [==============================] - 49s 975ms/step - loss: 4.1806 - ACC: 0.4973 - PPL: 67.1049 - val_loss: 4.1785 - val_ACC: 0.5044 - val_PPL: 65.4643\n",
      "Epoch 42/125\n",
      "49/50 [============================>.] - ETA: 0s - loss: 4.1338 - ACC: 0.5083 - PPL: 63.4504\n",
      "Epoch 00042: val_PPL improved from 65.46428 to 61.68813, saving model to ./model/model.keras\n",
      "50/50 [==============================] - 54s 1s/step - loss: 4.1320 - ACC: 0.5085 - PPL: 63.3234 - val_loss: 4.1185 - val_ACC: 0.5095 - val_PPL: 61.6881\n",
      "Epoch 43/125\n",
      "49/50 [============================>.] - ETA: 0s - loss: 4.1403 - ACC: 0.5057 - PPL: 64.2524\n",
      "Epoch 00043: val_PPL improved from 61.68813 to 60.51870, saving model to ./model/model.keras\n",
      "50/50 [==============================] - 48s 959ms/step - loss: 4.1399 - ACC: 0.5059 - PPL: 64.1932 - val_loss: 4.1002 - val_ACC: 0.5117 - val_PPL: 60.5187\n",
      "Epoch 44/125\n",
      "49/50 [============================>.] - ETA: 0s - loss: 4.0952 - ACC: 0.5105 - PPL: 61.0967\n",
      "Epoch 00044: val_PPL improved from 60.51870 to 58.48698, saving model to ./model/model.keras\n",
      "50/50 [==============================] - 49s 971ms/step - loss: 4.0906 - ACC: 0.5110 - PPL: 60.8269 - val_loss: 4.0661 - val_ACC: 0.5129 - val_PPL: 58.4870\n",
      "Epoch 45/125\n",
      "49/50 [============================>.] - ETA: 0s - loss: 4.0485 - ACC: 0.5152 - PPL: 58.6595\n",
      "Epoch 00045: val_PPL improved from 58.48698 to 55.66608, saving model to ./model/model.keras\n",
      "50/50 [==============================] - 48s 954ms/step - loss: 4.0470 - ACC: 0.5153 - PPL: 58.5489 - val_loss: 4.0161 - val_ACC: 0.5213 - val_PPL: 55.6661\n",
      "Epoch 46/125\n",
      "49/50 [============================>.] - ETA: 0s - loss: 4.0208 - ACC: 0.5194 - PPL: 56.9762\n",
      "Epoch 00046: val_PPL improved from 55.66608 to 55.32401, saving model to ./model/model.keras\n",
      "50/50 [==============================] - 49s 981ms/step - loss: 4.0212 - ACC: 0.5196 - PPL: 56.9733 - val_loss: 4.0113 - val_ACC: 0.5239 - val_PPL: 55.3240\n",
      "Epoch 47/125\n",
      "49/50 [============================>.] - ETA: 0s - loss: 3.9846 - ACC: 0.5212 - PPL: 54.9036\n",
      "Epoch 00047: val_PPL improved from 55.32401 to 54.38625, saving model to ./model/model.keras\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - 50s 1s/step - loss: 3.9875 - ACC: 0.5211 - PPL: 55.0477 - val_loss: 3.9939 - val_ACC: 0.5246 - val_PPL: 54.3862\n",
      "Epoch 48/125\n",
      "49/50 [============================>.] - ETA: 0s - loss: 4.0244 - ACC: 0.5190 - PPL: 56.8463\n",
      "Epoch 00048: val_PPL improved from 54.38625 to 52.48270, saving model to ./model/model.keras\n",
      "50/50 [==============================] - 48s 962ms/step - loss: 4.0246 - ACC: 0.5191 - PPL: 56.8389 - val_loss: 3.9584 - val_ACC: 0.5302 - val_PPL: 52.4827\n",
      "Epoch 49/125\n",
      "49/50 [============================>.] - ETA: 0s - loss: 3.9886 - ACC: 0.5238 - PPL: 54.8876\n",
      "Epoch 00049: val_PPL improved from 52.48270 to 51.39431, saving model to ./model/model.keras\n",
      "50/50 [==============================] - 57s 1s/step - loss: 3.9881 - ACC: 0.5238 - PPL: 54.8424 - val_loss: 3.9381 - val_ACC: 0.5324 - val_PPL: 51.3943\n",
      "Epoch 50/125\n",
      "49/50 [============================>.] - ETA: 0s - loss: 3.9273 - ACC: 0.5293 - PPL: 51.8083\n",
      "Epoch 00050: val_PPL improved from 51.39431 to 50.10671, saving model to ./model/model.keras\n",
      "50/50 [==============================] - 46s 921ms/step - loss: 3.9185 - ACC: 0.5300 - PPL: 51.4262 - val_loss: 3.9129 - val_ACC: 0.5369 - val_PPL: 50.1067\n",
      "Epoch 51/125\n",
      "49/50 [============================>.] - ETA: 0s - loss: 3.9198 - ACC: 0.5317 - PPL: 51.1997\n",
      "Epoch 00051: val_PPL improved from 50.10671 to 48.97948, saving model to ./model/model.keras\n",
      "50/50 [==============================] - 48s 960ms/step - loss: 3.9210 - ACC: 0.5315 - PPL: 51.2441 - val_loss: 3.8889 - val_ACC: 0.5383 - val_PPL: 48.9795\n",
      "Epoch 52/125\n",
      "49/50 [============================>.] - ETA: 0s - loss: 3.8393 - ACC: 0.5425 - PPL: 47.5578\n",
      "Epoch 00052: val_PPL improved from 48.97948 to 47.33639, saving model to ./model/model.keras\n",
      "50/50 [==============================] - 50s 1s/step - loss: 3.8466 - ACC: 0.5415 - PPL: 47.9460 - val_loss: 3.8548 - val_ACC: 0.5406 - val_PPL: 47.3364\n",
      "Epoch 53/125\n",
      "49/50 [============================>.] - ETA: 0s - loss: 3.7957 - ACC: 0.5440 - PPL: 45.3238\n",
      "Epoch 00053: val_PPL improved from 47.33639 to 46.21071, saving model to ./model/model.keras\n",
      "50/50 [==============================] - 47s 938ms/step - loss: 3.7902 - ACC: 0.5446 - PPL: 45.0942 - val_loss: 3.8306 - val_ACC: 0.5457 - val_PPL: 46.2107\n",
      "Epoch 54/125\n",
      "49/50 [============================>.] - ETA: 0s - loss: 3.8017 - ACC: 0.5440 - PPL: 45.4709\n",
      "Epoch 00054: val_PPL improved from 46.21071 to 44.46329, saving model to ./model/model.keras\n",
      "50/50 [==============================] - 48s 967ms/step - loss: 3.8014 - ACC: 0.5438 - PPL: 45.4440 - val_loss: 3.7924 - val_ACC: 0.5495 - val_PPL: 44.4633\n",
      "Epoch 55/125\n",
      "49/50 [============================>.] - ETA: 0s - loss: 3.8383 - ACC: 0.5426 - PPL: 47.2021\n",
      "Epoch 00055: val_PPL improved from 44.46329 to 42.70529, saving model to ./model/model.keras\n",
      "50/50 [==============================] - 49s 982ms/step - loss: 3.8341 - ACC: 0.5430 - PPL: 47.0090 - val_loss: 3.7518 - val_ACC: 0.5543 - val_PPL: 42.7053\n",
      "Epoch 56/125\n",
      "49/50 [============================>.] - ETA: 0s - loss: 3.7716 - ACC: 0.5520 - PPL: 44.2609\n",
      "Epoch 00056: val_PPL improved from 42.70529 to 42.29903, saving model to ./model/model.keras\n",
      "50/50 [==============================] - 49s 974ms/step - loss: 3.7727 - ACC: 0.5520 - PPL: 44.2926 - val_loss: 3.7420 - val_ACC: 0.5568 - val_PPL: 42.2990\n",
      "Epoch 57/125\n",
      "49/50 [============================>.] - ETA: 0s - loss: 3.7159 - ACC: 0.5557 - PPL: 42.1633\n",
      "Epoch 00057: val_PPL improved from 42.29903 to 41.72427, saving model to ./model/model.keras\n",
      "50/50 [==============================] - 49s 986ms/step - loss: 3.7177 - ACC: 0.5553 - PPL: 42.2191 - val_loss: 3.7288 - val_ACC: 0.5579 - val_PPL: 41.7243\n",
      "Epoch 58/125\n",
      "49/50 [============================>.] - ETA: 0s - loss: 3.7235 - ACC: 0.5538 - PPL: 42.3591\n",
      "Epoch 00058: val_PPL improved from 41.72427 to 41.00892, saving model to ./model/model.keras\n",
      "50/50 [==============================] - 49s 987ms/step - loss: 3.7270 - ACC: 0.5535 - PPL: 42.5008 - val_loss: 3.7109 - val_ACC: 0.5616 - val_PPL: 41.0089\n",
      "Epoch 59/125\n",
      "49/50 [============================>.] - ETA: 0s - loss: 3.6679 - ACC: 0.5590 - PPL: 39.9128\n",
      "Epoch 00059: val_PPL improved from 41.00892 to 39.41706, saving model to ./model/model.keras\n",
      "50/50 [==============================] - 49s 980ms/step - loss: 3.6680 - ACC: 0.5590 - PPL: 39.8987 - val_loss: 3.6721 - val_ACC: 0.5655 - val_PPL: 39.4171\n",
      "Epoch 60/125\n",
      "49/50 [============================>.] - ETA: 0s - loss: 3.6323 - ACC: 0.5657 - PPL: 38.5248\n",
      "Epoch 00060: val_PPL improved from 39.41706 to 37.62771, saving model to ./model/model.keras\n",
      "50/50 [==============================] - 51s 1s/step - loss: 3.6329 - ACC: 0.5663 - PPL: 38.5315 - val_loss: 3.6253 - val_ACC: 0.5704 - val_PPL: 37.6277\n",
      "Epoch 61/125\n",
      "49/50 [============================>.] - ETA: 0s - loss: 3.6108 - ACC: 0.5679 - PPL: 37.6216\n",
      "Epoch 00061: val_PPL improved from 37.62771 to 36.76819, saving model to ./model/model.keras\n",
      "50/50 [==============================] - 49s 987ms/step - loss: 3.6127 - ACC: 0.5680 - PPL: 37.6805 - val_loss: 3.6029 - val_ACC: 0.5746 - val_PPL: 36.7682\n",
      "Epoch 62/125\n",
      "49/50 [============================>.] - ETA: 0s - loss: 3.6124 - ACC: 0.5681 - PPL: 37.8398\n",
      "Epoch 00062: val_PPL improved from 36.76819 to 36.68716, saving model to ./model/model.keras\n",
      "50/50 [==============================] - 48s 950ms/step - loss: 3.6049 - ACC: 0.5690 - PPL: 37.5933 - val_loss: 3.5998 - val_ACC: 0.5740 - val_PPL: 36.6872\n",
      "Epoch 63/125\n",
      "49/50 [============================>.] - ETA: 0s - loss: 3.6363 - ACC: 0.5666 - PPL: 38.4763\n",
      "Epoch 00063: val_PPL did not improve\n",
      "50/50 [==============================] - 37s 748ms/step - loss: 3.6385 - ACC: 0.5666 - PPL: 38.5531 - val_loss: 3.6063 - val_ACC: 0.5718 - val_PPL: 36.9330\n",
      "Epoch 64/125\n",
      "49/50 [============================>.] - ETA: 0s - loss: 3.5857 - ACC: 0.5722 - PPL: 36.8822\n",
      "Epoch 00064: val_PPL improved from 36.68716 to 35.78161, saving model to ./model/model.keras\n",
      "50/50 [==============================] - 51s 1s/step - loss: 3.5914 - ACC: 0.5718 - PPL: 37.1060 - val_loss: 3.5746 - val_ACC: 0.5781 - val_PPL: 35.7816\n",
      "Epoch 65/125\n",
      "49/50 [============================>.] - ETA: 0s - loss: 3.5133 - ACC: 0.5803 - PPL: 34.3988\n",
      "Epoch 00065: val_PPL improved from 35.78161 to 33.40895, saving model to ./model/model.keras\n",
      "50/50 [==============================] - 49s 988ms/step - loss: 3.5138 - ACC: 0.5800 - PPL: 34.4003 - val_loss: 3.5067 - val_ACC: 0.5857 - val_PPL: 33.4089\n",
      "Epoch 66/125\n",
      "49/50 [============================>.] - ETA: 0s - loss: 3.5095 - ACC: 0.5815 - PPL: 33.9376\n",
      "Epoch 00066: val_PPL did not improve\n",
      "50/50 [==============================] - 38s 750ms/step - loss: 3.5060 - ACC: 0.5818 - PPL: 33.8211 - val_loss: 3.5339 - val_ACC: 0.5830 - val_PPL: 34.3108\n",
      "Epoch 67/125\n",
      "49/50 [============================>.] - ETA: 0s - loss: 3.4315 - ACC: 0.5924 - PPL: 31.3888\n",
      "Epoch 00067: val_PPL improved from 33.40895 to 33.20937, saving model to ./model/model.keras\n",
      "50/50 [==============================] - 52s 1s/step - loss: 3.4357 - ACC: 0.5920 - PPL: 31.5237 - val_loss: 3.5002 - val_ACC: 0.5863 - val_PPL: 33.2094\n",
      "Epoch 68/125\n",
      "49/50 [============================>.] - ETA: 0s - loss: 3.4338 - ACC: 0.5902 - PPL: 31.8528\n",
      "Epoch 00068: val_PPL improved from 33.20937 to 32.12215, saving model to ./model/model.keras\n",
      "50/50 [==============================] - 50s 1s/step - loss: 3.4431 - ACC: 0.5894 - PPL: 32.2040 - val_loss: 3.4673 - val_ACC: 0.5906 - val_PPL: 32.1222\n",
      "Epoch 69/125\n",
      "49/50 [============================>.] - ETA: 0s - loss: 3.4063 - ACC: 0.5910 - PPL: 30.8075\n",
      "Epoch 00069: val_PPL improved from 32.12215 to 31.87220, saving model to ./model/model.keras\n",
      "50/50 [==============================] - 49s 980ms/step - loss: 3.4151 - ACC: 0.5903 - PPL: 31.1265 - val_loss: 3.4594 - val_ACC: 0.5916 - val_PPL: 31.8722\n",
      "Epoch 70/125\n",
      "49/50 [============================>.] - ETA: 0s - loss: 3.4202 - ACC: 0.5913 - PPL: 31.1770\n",
      "Epoch 00070: val_PPL improved from 31.87220 to 30.71492, saving model to ./model/model.keras\n",
      "50/50 [==============================] - 49s 982ms/step - loss: 3.4186 - ACC: 0.5914 - PPL: 31.1176 - val_loss: 3.4225 - val_ACC: 0.5961 - val_PPL: 30.7149\n",
      "Epoch 71/125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49/50 [============================>.] - ETA: 0s - loss: 3.3954 - ACC: 0.5942 - PPL: 30.4969\n",
      "Epoch 00071: val_PPL improved from 30.71492 to 29.98598, saving model to ./model/model.keras\n",
      "50/50 [==============================] - 50s 1s/step - loss: 3.3953 - ACC: 0.5946 - PPL: 30.4809 - val_loss: 3.3984 - val_ACC: 0.5992 - val_PPL: 29.9860\n",
      "Epoch 72/125\n",
      "49/50 [============================>.] - ETA: 0s - loss: 3.3735 - ACC: 0.5939 - PPL: 29.6577\n",
      "Epoch 00072: val_PPL improved from 29.98598 to 29.22564, saving model to ./model/model.keras\n",
      "50/50 [==============================] - 47s 950ms/step - loss: 3.3707 - ACC: 0.5942 - PPL: 29.5726 - val_loss: 3.3723 - val_ACC: 0.6025 - val_PPL: 29.2256\n",
      "Epoch 73/125\n",
      "49/50 [============================>.] - ETA: 0s - loss: 3.3632 - ACC: 0.6001 - PPL: 29.5922\n",
      "Epoch 00073: val_PPL improved from 29.22564 to 27.96350, saving model to ./model/model.keras\n",
      "50/50 [==============================] - 49s 970ms/step - loss: 3.3648 - ACC: 0.6002 - PPL: 29.6244 - val_loss: 3.3288 - val_ACC: 0.6078 - val_PPL: 27.9635\n",
      "Epoch 74/125\n",
      "49/50 [============================>.] - ETA: 0s - loss: 3.3573 - ACC: 0.5998 - PPL: 29.5629\n",
      "Epoch 00074: val_PPL did not improve\n",
      "50/50 [==============================] - 41s 826ms/step - loss: 3.3621 - ACC: 0.5993 - PPL: 29.7020 - val_loss: 3.3312 - val_ACC: 0.6077 - val_PPL: 28.0641\n",
      "Epoch 75/125\n",
      "49/50 [============================>.] - ETA: 0s - loss: 3.3176 - ACC: 0.6041 - PPL: 28.1584\n",
      "Epoch 00075: val_PPL improved from 27.96350 to 27.28043, saving model to ./model/model.keras\n",
      "50/50 [==============================] - 52s 1s/step - loss: 3.3202 - ACC: 0.6038 - PPL: 28.2252 - val_loss: 3.3038 - val_ACC: 0.6106 - val_PPL: 27.2804\n",
      "Epoch 76/125\n",
      "49/50 [============================>.] - ETA: 0s - loss: 3.2447 - ACC: 0.6116 - PPL: 25.9995\n",
      "Epoch 00076: val_PPL improved from 27.28043 to 26.94192, saving model to ./model/model.keras\n",
      "50/50 [==============================] - 51s 1s/step - loss: 3.2431 - ACC: 0.6116 - PPL: 25.9536 - val_loss: 3.2917 - val_ACC: 0.6130 - val_PPL: 26.9419\n",
      "Epoch 77/125\n",
      "49/50 [============================>.] - ETA: 0s - loss: 3.2144 - ACC: 0.6171 - PPL: 25.2706\n",
      "Epoch 00077: val_PPL improved from 26.94192 to 26.58745, saving model to ./model/model.keras\n",
      "50/50 [==============================] - 47s 946ms/step - loss: 3.2082 - ACC: 0.6178 - PPL: 25.1301 - val_loss: 3.2778 - val_ACC: 0.6129 - val_PPL: 26.5875\n",
      "Epoch 78/125\n",
      "49/50 [============================>.] - ETA: 0s - loss: 3.1763 - ACC: 0.6188 - PPL: 24.4043\n",
      "Epoch 00078: val_PPL improved from 26.58745 to 24.80995, saving model to ./model/model.keras\n",
      "50/50 [==============================] - 47s 948ms/step - loss: 3.1811 - ACC: 0.6185 - PPL: 24.5243 - val_loss: 3.2093 - val_ACC: 0.6210 - val_PPL: 24.8100\n",
      "Epoch 79/125\n",
      "49/50 [============================>.] - ETA: 0s - loss: 3.2543 - ACC: 0.6113 - PPL: 26.4095\n",
      "Epoch 00079: val_PPL did not improve\n",
      "50/50 [==============================] - 38s 764ms/step - loss: 3.2536 - ACC: 0.6114 - PPL: 26.3808 - val_loss: 3.2277 - val_ACC: 0.6208 - val_PPL: 25.2767\n",
      "Epoch 80/125\n",
      "49/50 [============================>.] - ETA: 0s - loss: 3.1942 - ACC: 0.6165 - PPL: 24.9322\n",
      "Epoch 00080: val_PPL improved from 24.80995 to 24.74041, saving model to ./model/model.keras\n",
      "50/50 [==============================] - 52s 1s/step - loss: 3.1929 - ACC: 0.6167 - PPL: 24.8925 - val_loss: 3.2041 - val_ACC: 0.6229 - val_PPL: 24.7404\n",
      "Epoch 81/125\n",
      "49/50 [============================>.] - ETA: 0s - loss: 3.1985 - ACC: 0.6198 - PPL: 24.9477\n",
      "Epoch 00081: val_PPL did not improve\n",
      "50/50 [==============================] - 38s 767ms/step - loss: 3.2061 - ACC: 0.6192 - PPL: 25.1627 - val_loss: 3.2069 - val_ACC: 0.6236 - val_PPL: 24.7592\n",
      "Epoch 82/125\n",
      "49/50 [============================>.] - ETA: 0s - loss: 3.0812 - ACC: 0.6302 - PPL: 22.2134\n",
      "Epoch 00082: val_PPL improved from 24.74041 to 23.89761, saving model to ./model/model.keras\n",
      "50/50 [==============================] - 51s 1s/step - loss: 3.0876 - ACC: 0.6296 - PPL: 22.3693 - val_loss: 3.1722 - val_ACC: 0.6269 - val_PPL: 23.8976\n",
      "Epoch 83/125\n",
      "49/50 [============================>.] - ETA: 0s - loss: 3.1500 - ACC: 0.6237 - PPL: 23.7083\n",
      "Epoch 00083: val_PPL improved from 23.89761 to 22.95500, saving model to ./model/model.keras\n",
      "50/50 [==============================] - 49s 989ms/step - loss: 3.1478 - ACC: 0.6239 - PPL: 23.6524 - val_loss: 3.1307 - val_ACC: 0.6307 - val_PPL: 22.9550\n",
      "Epoch 84/125\n",
      "49/50 [============================>.] - ETA: 0s - loss: 3.1396 - ACC: 0.6232 - PPL: 23.4672\n",
      "Epoch 00084: val_PPL improved from 22.95500 to 22.73724, saving model to ./model/model.keras\n",
      "50/50 [==============================] - 48s 965ms/step - loss: 3.1356 - ACC: 0.6240 - PPL: 23.3764 - val_loss: 3.1224 - val_ACC: 0.6323 - val_PPL: 22.7372\n",
      "Epoch 85/125\n",
      "49/50 [============================>.] - ETA: 0s - loss: 3.0562 - ACC: 0.6356 - PPL: 21.6362\n",
      "Epoch 00085: val_PPL improved from 22.73724 to 22.12837, saving model to ./model/model.keras\n",
      "50/50 [==============================] - 49s 970ms/step - loss: 3.0573 - ACC: 0.6357 - PPL: 21.6514 - val_loss: 3.0940 - val_ACC: 0.6359 - val_PPL: 22.1284\n",
      "Epoch 86/125\n",
      "49/50 [============================>.] - ETA: 0s - loss: 3.0310 - ACC: 0.6384 - PPL: 20.9799\n",
      "Epoch 00086: val_PPL improved from 22.12837 to 21.88874, saving model to ./model/model.keras\n",
      "50/50 [==============================] - 46s 926ms/step - loss: 3.0312 - ACC: 0.6384 - PPL: 20.9787 - val_loss: 3.0833 - val_ACC: 0.6359 - val_PPL: 21.8887\n",
      "Epoch 87/125\n",
      "49/50 [============================>.] - ETA: 0s - loss: 3.0509 - ACC: 0.6342 - PPL: 21.5732\n",
      "Epoch 00087: val_PPL did not improve\n",
      "50/50 [==============================] - 39s 778ms/step - loss: 3.0471 - ACC: 0.6344 - PPL: 21.4911 - val_loss: 3.0856 - val_ACC: 0.6362 - val_PPL: 21.9359\n",
      "Epoch 88/125\n",
      "49/50 [============================>.] - ETA: 0s - loss: 2.9686 - ACC: 0.6438 - PPL: 19.7765\n",
      "Epoch 00088: val_PPL improved from 21.88874 to 20.81670, saving model to ./model/model.keras\n",
      "50/50 [==============================] - 52s 1s/step - loss: 2.9720 - ACC: 0.6434 - PPL: 19.8430 - val_loss: 3.0339 - val_ACC: 0.6439 - val_PPL: 20.8167\n",
      "Epoch 89/125\n",
      "49/50 [============================>.] - ETA: 0s - loss: 2.9979 - ACC: 0.6401 - PPL: 20.4441\n",
      "Epoch 00089: val_PPL did not improve\n",
      "50/50 [==============================] - 38s 762ms/step - loss: 2.9967 - ACC: 0.6400 - PPL: 20.4138 - val_loss: 3.0366 - val_ACC: 0.6414 - val_PPL: 20.8836\n",
      "Epoch 90/125\n",
      "49/50 [============================>.] - ETA: 0s - loss: 3.0089 - ACC: 0.6375 - PPL: 20.7128\n",
      "Epoch 00090: val_PPL improved from 20.81670 to 20.30966, saving model to ./model/model.keras\n",
      "50/50 [==============================] - 51s 1s/step - loss: 3.0086 - ACC: 0.6375 - PPL: 20.6982 - val_loss: 3.0084 - val_ACC: 0.6464 - val_PPL: 20.3097\n",
      "Epoch 91/125\n",
      "49/50 [============================>.] - ETA: 0s - loss: 2.9620 - ACC: 0.6468 - PPL: 19.5947\n",
      "Epoch 00091: val_PPL improved from 20.30966 to 19.59931, saving model to ./model/model.keras\n",
      "50/50 [==============================] - 52s 1s/step - loss: 2.9584 - ACC: 0.6472 - PPL: 19.5269 - val_loss: 2.9730 - val_ACC: 0.6507 - val_PPL: 19.5993\n",
      "Epoch 92/125\n",
      "49/50 [============================>.] - ETA: 0s - loss: 2.9141 - ACC: 0.6504 - PPL: 18.7714\n",
      "Epoch 00092: val_PPL improved from 19.59931 to 19.26050, saving model to ./model/model.keras\n",
      "50/50 [==============================] - 49s 987ms/step - loss: 2.9186 - ACC: 0.6497 - PPL: 18.8567 - val_loss: 2.9555 - val_ACC: 0.6521 - val_PPL: 19.2605\n",
      "Epoch 93/125\n",
      "49/50 [============================>.] - ETA: 0s - loss: 2.9326 - ACC: 0.6490 - PPL: 19.2490\n",
      "Epoch 00093: val_PPL improved from 19.26050 to 18.96883, saving model to ./model/model.keras\n",
      "50/50 [==============================] - 49s 971ms/step - loss: 2.9368 - ACC: 0.6483 - PPL: 19.3273 - val_loss: 2.9407 - val_ACC: 0.6530 - val_PPL: 18.9688\n",
      "Epoch 94/125\n",
      "49/50 [============================>.] - ETA: 0s - loss: 2.8924 - ACC: 0.6534 - PPL: 18.4283\n",
      "Epoch 00094: val_PPL improved from 18.96883 to 18.73024, saving model to ./model/model.keras\n",
      "50/50 [==============================] - 49s 972ms/step - loss: 2.8899 - ACC: 0.6538 - PPL: 18.3788 - val_loss: 2.9276 - val_ACC: 0.6559 - val_PPL: 18.7302\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 95/125\n",
      "49/50 [============================>.] - ETA: 0s - loss: 2.8701 - ACC: 0.6541 - PPL: 17.9744\n",
      "Epoch 00095: val_PPL improved from 18.73024 to 18.20503, saving model to ./model/model.keras\n",
      "50/50 [==============================] - 47s 948ms/step - loss: 2.8650 - ACC: 0.6543 - PPL: 17.8879 - val_loss: 2.8990 - val_ACC: 0.6584 - val_PPL: 18.2050\n",
      "Epoch 96/125\n",
      "49/50 [============================>.] - ETA: 0s - loss: 2.9446 - ACC: 0.6443 - PPL: 19.4890\n",
      "Epoch 00096: val_PPL improved from 18.20503 to 18.08504, saving model to ./model/model.keras\n",
      "50/50 [==============================] - 49s 971ms/step - loss: 2.9461 - ACC: 0.6443 - PPL: 19.5107 - val_loss: 2.8932 - val_ACC: 0.6597 - val_PPL: 18.0850\n",
      "Epoch 97/125\n",
      "49/50 [============================>.] - ETA: 0s - loss: 2.8663 - ACC: 0.6547 - PPL: 17.8291\n",
      "Epoch 00097: val_PPL improved from 18.08504 to 17.56852, saving model to ./model/model.keras\n",
      "50/50 [==============================] - 50s 993ms/step - loss: 2.8660 - ACC: 0.6545 - PPL: 17.8198 - val_loss: 2.8630 - val_ACC: 0.6640 - val_PPL: 17.5685\n",
      "Epoch 98/125\n",
      "49/50 [============================>.] - ETA: 0s - loss: 2.8036 - ACC: 0.6627 - PPL: 16.8044\n",
      "Epoch 00098: val_PPL improved from 17.56852 to 17.42964, saving model to ./model/model.keras\n",
      "50/50 [==============================] - 48s 963ms/step - loss: 2.8002 - ACC: 0.6626 - PPL: 16.7469 - val_loss: 2.8562 - val_ACC: 0.6623 - val_PPL: 17.4296\n",
      "Epoch 99/125\n",
      "49/50 [============================>.] - ETA: 0s - loss: 2.8279 - ACC: 0.6600 - PPL: 17.1310\n",
      "Epoch 00099: val_PPL improved from 17.42964 to 16.90057, saving model to ./model/model.keras\n",
      "50/50 [==============================] - 48s 957ms/step - loss: 2.8325 - ACC: 0.6594 - PPL: 17.2151 - val_loss: 2.8252 - val_ACC: 0.6669 - val_PPL: 16.9006\n",
      "Epoch 100/125\n",
      "49/50 [============================>.] - ETA: 0s - loss: 2.7982 - ACC: 0.6652 - PPL: 16.7406\n",
      "Epoch 00100: val_PPL improved from 16.90057 to 16.63841, saving model to ./model/model.keras\n",
      "50/50 [==============================] - 48s 964ms/step - loss: 2.7979 - ACC: 0.6653 - PPL: 16.7297 - val_loss: 2.8092 - val_ACC: 0.6690 - val_PPL: 16.6384\n",
      "Epoch 101/125\n",
      "49/50 [============================>.] - ETA: 0s - loss: 2.7442 - ACC: 0.6704 - PPL: 15.8311\n",
      "Epoch 00101: val_PPL did not improve\n",
      "50/50 [==============================] - 37s 749ms/step - loss: 2.7549 - ACC: 0.6692 - PPL: 16.0480 - val_loss: 2.8113 - val_ACC: 0.6678 - val_PPL: 16.6804\n",
      "Epoch 102/125\n",
      "49/50 [============================>.] - ETA: 0s - loss: 2.7466 - ACC: 0.6689 - PPL: 15.9256\n",
      "Epoch 00102: val_PPL improved from 16.63841 to 15.85200, saving model to ./model/model.keras\n",
      "50/50 [==============================] - 50s 1000ms/step - loss: 2.7454 - ACC: 0.6688 - PPL: 15.9004 - val_loss: 2.7613 - val_ACC: 0.6746 - val_PPL: 15.8520\n",
      "Epoch 103/125\n",
      "49/50 [============================>.] - ETA: 0s - loss: 2.7820 - ACC: 0.6653 - PPL: 16.6151\n",
      "Epoch 00103: val_PPL improved from 15.85200 to 15.81870, saving model to ./model/model.keras\n",
      "50/50 [==============================] - 49s 985ms/step - loss: 2.7852 - ACC: 0.6646 - PPL: 16.6617 - val_loss: 2.7582 - val_ACC: 0.6749 - val_PPL: 15.8187\n",
      "Epoch 104/125\n",
      "49/50 [============================>.] - ETA: 0s - loss: 2.7512 - ACC: 0.6672 - PPL: 16.0438\n",
      "Epoch 00104: val_PPL improved from 15.81870 to 15.66297, saving model to ./model/model.keras\n",
      "50/50 [==============================] - 48s 967ms/step - loss: 2.7446 - ACC: 0.6681 - PPL: 15.9482 - val_loss: 2.7503 - val_ACC: 0.6757 - val_PPL: 15.6630\n",
      "Epoch 105/125\n",
      "49/50 [============================>.] - ETA: 0s - loss: 2.6460 - ACC: 0.6795 - PPL: 14.3723\n",
      "Epoch 00105: val_PPL improved from 15.66297 to 15.45362, saving model to ./model/model.keras\n",
      "50/50 [==============================] - 47s 947ms/step - loss: 2.6476 - ACC: 0.6794 - PPL: 14.3912 - val_loss: 2.7355 - val_ACC: 0.6766 - val_PPL: 15.4536\n",
      "Epoch 106/125\n",
      "49/50 [============================>.] - ETA: 0s - loss: 2.7115 - ACC: 0.6738 - PPL: 15.3939\n",
      "Epoch 00106: val_PPL improved from 15.45362 to 14.94254, saving model to ./model/model.keras\n",
      "50/50 [==============================] - 48s 953ms/step - loss: 2.7070 - ACC: 0.6742 - PPL: 15.3270 - val_loss: 2.7004 - val_ACC: 0.6810 - val_PPL: 14.9425\n",
      "Epoch 107/125\n",
      "49/50 [============================>.] - ETA: 0s - loss: 2.6877 - ACC: 0.6738 - PPL: 14.9200\n",
      "Epoch 00107: val_PPL improved from 14.94254 to 14.68715, saving model to ./model/model.keras\n",
      "50/50 [==============================] - 50s 997ms/step - loss: 2.6875 - ACC: 0.6738 - PPL: 14.9120 - val_loss: 2.6840 - val_ACC: 0.6836 - val_PPL: 14.6872\n",
      "Epoch 108/125\n",
      "49/50 [============================>.] - ETA: 0s - loss: 2.6496 - ACC: 0.6817 - PPL: 14.3701\n",
      "Epoch 00108: val_PPL improved from 14.68715 to 14.52031, saving model to ./model/model.keras\n",
      "50/50 [==============================] - 47s 946ms/step - loss: 2.6498 - ACC: 0.6815 - PPL: 14.3687 - val_loss: 2.6701 - val_ACC: 0.6845 - val_PPL: 14.5203\n",
      "Epoch 109/125\n",
      "49/50 [============================>.] - ETA: 0s - loss: 2.6390 - ACC: 0.6809 - PPL: 14.2222\n",
      "Epoch 00109: val_PPL improved from 14.52031 to 13.85215, saving model to ./model/model.keras\n",
      "50/50 [==============================] - 47s 943ms/step - loss: 2.6372 - ACC: 0.6812 - PPL: 14.1937 - val_loss: 2.6255 - val_ACC: 0.6908 - val_PPL: 13.8522\n",
      "Epoch 110/125\n",
      "49/50 [============================>.] - ETA: 0s - loss: 2.6408 - ACC: 0.6813 - PPL: 14.2900\n",
      "Epoch 00110: val_PPL did not improve\n",
      "50/50 [==============================] - 38s 767ms/step - loss: 2.6384 - ACC: 0.6814 - PPL: 14.2532 - val_loss: 2.6293 - val_ACC: 0.6907 - val_PPL: 13.9109\n",
      "Epoch 111/125\n",
      "49/50 [============================>.] - ETA: 0s - loss: 2.6103 - ACC: 0.6853 - PPL: 13.8219\n",
      "Epoch 00111: val_PPL did not improve\n",
      "50/50 [==============================] - 41s 823ms/step - loss: 2.6118 - ACC: 0.6851 - PPL: 13.8388 - val_loss: 2.6604 - val_ACC: 0.6865 - val_PPL: 14.3462\n",
      "Epoch 112/125\n",
      "49/50 [============================>.] - ETA: 0s - loss: 2.5603 - ACC: 0.6914 - PPL: 13.1526\n",
      "Epoch 00112: val_PPL did not improve\n",
      "50/50 [==============================] - 42s 831ms/step - loss: 2.5593 - ACC: 0.6916 - PPL: 13.1358 - val_loss: 2.6272 - val_ACC: 0.6902 - val_PPL: 13.8768\n",
      "Epoch 113/125\n",
      "49/50 [============================>.] - ETA: 0s - loss: 2.5740 - ACC: 0.6848 - PPL: 13.3703\n",
      "Epoch 00113: val_PPL improved from 13.85215 to 13.69853, saving model to ./model/model.keras\n",
      "50/50 [==============================] - 52s 1s/step - loss: 2.5697 - ACC: 0.6853 - PPL: 13.3137 - val_loss: 2.6146 - val_ACC: 0.6906 - val_PPL: 13.6985\n",
      "Epoch 114/125\n",
      "49/50 [============================>.] - ETA: 0s - loss: 2.5898 - ACC: 0.6870 - PPL: 13.5447\n",
      "Epoch 00114: val_PPL improved from 13.69853 to 13.29381, saving model to ./model/model.keras\n",
      "50/50 [==============================] - 48s 966ms/step - loss: 2.5935 - ACC: 0.6868 - PPL: 13.5942 - val_loss: 2.5847 - val_ACC: 0.6940 - val_PPL: 13.2938\n",
      "Epoch 115/125\n",
      "49/50 [============================>.] - ETA: 0s - loss: 2.5359 - ACC: 0.6913 - PPL: 12.8551\n",
      "Epoch 00115: val_PPL improved from 13.29381 to 13.26724, saving model to ./model/model.keras\n",
      "50/50 [==============================] - 47s 942ms/step - loss: 2.5367 - ACC: 0.6911 - PPL: 12.8606 - val_loss: 2.5823 - val_ACC: 0.6965 - val_PPL: 13.2672\n",
      "Epoch 116/125\n",
      "49/50 [============================>.] - ETA: 0s - loss: 2.5622 - ACC: 0.6902 - PPL: 13.2828\n",
      "Epoch 00116: val_PPL improved from 13.26724 to 12.83043, saving model to ./model/model.keras\n",
      "50/50 [==============================] - 48s 962ms/step - loss: 2.5689 - ACC: 0.6893 - PPL: 13.3795 - val_loss: 2.5491 - val_ACC: 0.6990 - val_PPL: 12.8304\n",
      "Epoch 117/125\n",
      "49/50 [============================>.] - ETA: 0s - loss: 2.4711 - ACC: 0.7017 - PPL: 12.0197\n",
      "Epoch 00117: val_PPL improved from 12.83043 to 12.55900, saving model to ./model/model.keras\n",
      "50/50 [==============================] - 50s 1s/step - loss: 2.4658 - ACC: 0.7023 - PPL: 11.9607 - val_loss: 2.5287 - val_ACC: 0.7010 - val_PPL: 12.5590\n",
      "Epoch 118/125\n",
      "49/50 [============================>.] - ETA: 0s - loss: 2.4552 - ACC: 0.7034 - PPL: 11.8156\n",
      "Epoch 00118: val_PPL improved from 12.55900 to 12.54372, saving model to ./model/model.keras\n",
      "50/50 [==============================] - 48s 958ms/step - loss: 2.4590 - ACC: 0.7031 - PPL: 11.8614 - val_loss: 2.5256 - val_ACC: 0.7014 - val_PPL: 12.5437\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 119/125\n",
      "49/50 [============================>.] - ETA: 0s - loss: 2.4422 - ACC: 0.7048 - PPL: 11.7102\n",
      "Epoch 00119: val_PPL improved from 12.54372 to 12.32998, saving model to ./model/model.keras\n",
      "50/50 [==============================] - 48s 967ms/step - loss: 2.4399 - ACC: 0.7049 - PPL: 11.6814 - val_loss: 2.5094 - val_ACC: 0.7035 - val_PPL: 12.3300\n",
      "Epoch 120/125\n",
      "49/50 [============================>.] - ETA: 0s - loss: 2.3918 - ACC: 0.7065 - PPL: 11.1155\n",
      "Epoch 00120: val_PPL improved from 12.32998 to 12.18490, saving model to ./model/model.keras\n",
      "50/50 [==============================] - 49s 986ms/step - loss: 2.3889 - ACC: 0.7069 - PPL: 11.0826 - val_loss: 2.4976 - val_ACC: 0.7053 - val_PPL: 12.1849\n",
      "Epoch 121/125\n",
      "49/50 [============================>.] - ETA: 0s - loss: 2.4600 - ACC: 0.7012 - PPL: 11.9839\n",
      "Epoch 00121: val_PPL improved from 12.18490 to 11.68638, saving model to ./model/model.keras\n",
      "50/50 [==============================] - 47s 948ms/step - loss: 2.4612 - ACC: 0.7011 - PPL: 11.9934 - val_loss: 2.4558 - val_ACC: 0.7092 - val_PPL: 11.6864\n",
      "Epoch 122/125\n",
      "49/50 [============================>.] - ETA: 0s - loss: 2.3689 - ACC: 0.7138 - PPL: 10.8495\n",
      "Epoch 00122: val_PPL improved from 11.68638 to 11.46058, saving model to ./model/model.keras\n",
      "50/50 [==============================] - 48s 965ms/step - loss: 2.3695 - ACC: 0.7135 - PPL: 10.8526 - val_loss: 2.4367 - val_ACC: 0.7109 - val_PPL: 11.4606\n",
      "Epoch 123/125\n",
      "49/50 [============================>.] - ETA: 0s - loss: 2.4115 - ACC: 0.7070 - PPL: 11.3246\n",
      "Epoch 00123: val_PPL improved from 11.46058 to 11.28648, saving model to ./model/model.keras\n",
      "50/50 [==============================] - 46s 921ms/step - loss: 2.4132 - ACC: 0.7069 - PPL: 11.3410 - val_loss: 2.4222 - val_ACC: 0.7140 - val_PPL: 11.2865\n",
      "Epoch 124/125\n",
      "49/50 [============================>.] - ETA: 0s - loss: 2.3433 - ACC: 0.7149 - PPL: 10.5893\n",
      "Epoch 00124: val_PPL improved from 11.28648 to 11.23059, saving model to ./model/model.keras\n",
      "50/50 [==============================] - 50s 997ms/step - loss: 2.3430 - ACC: 0.7150 - PPL: 10.5830 - val_loss: 2.4171 - val_ACC: 0.7147 - val_PPL: 11.2306\n",
      "Epoch 125/125\n",
      "49/50 [============================>.] - ETA: 0s - loss: 2.3307 - ACC: 0.7166 - PPL: 10.4322\n",
      "Epoch 00125: val_PPL did not improve\n",
      "50/50 [==============================] - 38s 756ms/step - loss: 2.3276 - ACC: 0.7173 - PPL: 10.4004 - val_loss: 2.4251 - val_ACC: 0.7141 - val_PPL: 11.3320\n"
     ]
    }
   ],
   "source": [
    "history = gCNNModel.fit_generator(generator=gen_word_word(batch_size=16), \n",
    "                           steps_per_epoch=50, epochs=125,\n",
    "                           callbacks=callback_lists,\n",
    "                           validation_data=gen_word_word(dataset='valid'),\n",
    "                           validation_steps=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Keras - Character-Aware Neural Language Models.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
